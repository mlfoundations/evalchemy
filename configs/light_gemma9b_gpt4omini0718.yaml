# Gemma is 9B and gets OOM using the other set of configs. 
annotator_model: gpt-4o-mini-2024-07-18
tasks:
  - task_name: alpaca_eval
    batch_size: 1
  - task_name: WildBench
    batch_size: 1
  - task_name: MixEval
    batch_size: 1
  - task_name: MTBench
    batch_size: 1
  - task_name: IFEval
    batch_size: 1
  - task_name: mmlu
    batch_size: 1
  - task_name: ai2_arc
    batch_size: 1
  - task_name: HumanEval
    batch_size: 1
  - task_name: MBPP
    batch_size: 1
  - task_name: drop
    batch_size: 1
  - task_name: hendrycks_math
    batch_size: 1