# BBEH NYCC

This task builds on the existing benchmarks for the New Yorker Caption Contest
(NYCC) dataset (see [this work](https://arxiv.org/abs/2209.06293) and
[this work](https://arxiv.org/abs/2406.10522)). The NYCC caption dataset
consists of a: several hundred contests, each of which is a cartoon published
in the New Yorker magazine and several thousand submitted humorous captions,
b: crowdsourced ratings for each caption. The ratings are on a scale of
**Unfunny**, **Somewhat Funny**, and **Funny**, and each caption has anywhere
from a few dozen to a few thousand ratings. Past works have focused on pairwise
comparison tasks, where two captions and a textual description of the cartoon
are presented to the model, and the model has to pick the funnier of the two.
To make the task significantly more difficult, for each contest we sample one
query from the top ten rated, and then take captions ranked 1000-1009 and ask
the model to choose the funniest. We use the textual descriptions of the
cartoons generated by GPT-4o that are provided in
[this work](https://arxiv.org/abs/2406.10522).
