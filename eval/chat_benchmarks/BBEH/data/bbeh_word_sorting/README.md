# BBEH Word Sorting

This task is composed of two subtasks.

Subtask 1: This subtask is from the
[BIG-Bench Mistake](https://arxiv.org/pdf/2311.08516). This task involves
finding the first mistake in an existing chain-of-thought sequence, used to
answer a Word Sorting question in the original BBH dataset. In each example,
the target answer is either the number where the first mistake occurred, or
that there are no mistakes in the CoT sequence. These CoT sequences are
generated by prompting PaLM 2 Unicorn on the original BBH dataset at
temperature = 0. The newline is used as a stop token so that each
intermediate step can be prepended with *Thought 1:* , *Thought 2: *, etc.
Further information on the prompting and generation process can be found in
the original work.

Subtask 2: The second sub-task is sorting a list of words given a new
alphabet order (examples include: an alphabet order that is the same as
English but two letters are swapped in the order, an alphabet order that is
the same as English but one/two letters are moved to the beginning/end of the
order, or a completely new order). This task requires going against a strong
prior and sorting words in a non-typical way.
