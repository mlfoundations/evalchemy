{
  "gpt-4o-2024-05-13": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "57.5",
    "AE2.0": "51.3",
    "Arena Elo (hard-en) - 2024-07-16": 1280,
    "Arena Elo (hard-en) - latest": 1280,
    "haiku_reward.K=500": 30.46875,
    "llama_reward.K=500": 47.8515625,
    "gpt4t_reward.K=500": -4.052734375,
    "haiku_reward.Creative Tasks.K=500": 31.345565749235476,
    "llama_reward.Creative Tasks.K=500": 40.063091482649845,
    "gpt4t_reward.Creative Tasks.K=500": -12.006079027355623,
    "mixture_of_rewards.Creative Tasks.K=500": 19.800859401509896,
    "haiku_reward.Planning & Reasoning.K=500": 36.706689536878216,
    "llama_reward.Planning & Reasoning.K=500": 58.94097222222222,
    "gpt4t_reward.Planning & Reasoning.K=500": -2.5684931506849313,
    "mixture_of_rewards.Planning & Reasoning.K=500": 31.0263895361385,
    "haiku_reward.Math & Data Analysis.K=500": 45.474137931034484,
    "llama_reward.Math & Data Analysis.K=500": 74.67532467532467,
    "gpt4t_reward.Math & Data Analysis.K=500": -0.6521739130434783,
    "mixture_of_rewards.Math & Data Analysis.K=500": 39.832429564438556,
    "haiku_reward.Information/Advice seeking.K=500": 27.882037533512065,
    "llama_reward.Information/Advice seeking.K=500": 47.97843665768194,
    "gpt4t_reward.Information/Advice seeking.K=500": 2.1447721179624666,
    "mixture_of_rewards.Information/Advice seeking.K=500": 26.00174876971882,
    "haiku_reward.Coding & Debugging.K=500": 42.77456647398844,
    "llama_reward.Coding & Debugging.K=500": 72.25433526011561,
    "gpt4t_reward.Coding & Debugging.K=500": -7.142857142857142,
    "mixture_of_rewards.Coding & Debugging.K=500": 35.96201486374897,
    "haiku_reward.task_macro.K=500": 38.191582940919915,
    "llama_reward.task_macro.K=500": 62.03891205533334,
    "gpt4t_reward.task_macro.K=500": -3.618067832668849,
    "mixture_of_rewards.K=500": 24.755859375,
    "task_macro_reward.K=500": 32.204142387861474,
    "WB_score.Creative Tasks": 59.12144702842377,
    "WB_score.Planning & Reasoning": 60.20958083832337,
    "WB_score.Math & Data Analysis": 57.29083665338646,
    "WB_score.Information/Advice seeking": 58.61386138613861,
    "WB_score.Coding & Debugging": 60.473933649289116,
    "WB_score": 58.80742913000978,
    "WB_score.task_macro": 59.298178803519555,
    "Length": 3723.516129032258,
    "Rank_ScoreMacro": 2,
    "Rank_TaskMacroReward.K": 3,
    "Rank_Avg": 2.5,
    "RewardScore_Avg": 45.751160595690514,
    "WB_Elo": 1239.4730859477231
  },
  "gpt-4-turbo-2024-04-09": {
    "Arena-Hard v0.1": "82.6",
    "AE2.0 LC": "55",
    "AE2.0": "46.1",
    "Arena Elo (hard-en) - 2024-07-16": 1247,
    "Arena Elo (hard-en) - latest": 1247,
    "haiku_reward.K=500": 31.93359375,
    "llama_reward.K=500": 51.611328125,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 36.657303370786515,
    "llama_reward.Creative Tasks.K=500": 45.352112676056336,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 27.336472015614287,
    "haiku_reward.Planning & Reasoning.K=500": 33.30670926517572,
    "llama_reward.Planning & Reasoning.K=500": 57.085346215780994,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 30.130685160318905,
    "haiku_reward.Math & Data Analysis.K=500": 34.85477178423236,
    "llama_reward.Math & Data Analysis.K=500": 70.20833333333333,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 35.02103503918857,
    "haiku_reward.Information/Advice seeking.K=500": 26.282051282051285,
    "llama_reward.Information/Advice seeking.K=500": 46.282051282051285,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 24.18803418803419,
    "haiku_reward.Coding & Debugging.K=500": 37.22826086956522,
    "llama_reward.Coding & Debugging.K=500": 76.64835164835165,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 37.958870839305625,
    "haiku_reward.task_macro.K=500": 33.908142020966366,
    "llama_reward.task_macro.K=500": 62.055379044855954,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 27.848307291666668,
    "task_macro_reward.K=500": 31.987840355274106,
    "WB_score.Creative Tasks": 58.65633074935401,
    "WB_score.Planning & Reasoning": 56.203288490284,
    "WB_score.Math & Data Analysis": 50.99601593625499,
    "WB_score.Information/Advice seeking": 57.178217821782184,
    "WB_score.Coding & Debugging": 55.071090047393355,
    "WB_score": 56.089931573802545,
    "WB_score.task_macro": 55.22122481039269,
    "Length": 3093.1700879765394,
    "Rank_ScoreMacro": 6,
    "Rank_TaskMacroReward.K": 4,
    "Rank_Avg": 5.0,
    "RewardScore_Avg": 43.6045325828334,
    "WB_Elo": 1222.6896973319426
  },
  "gpt-4-0125-preview": {
    "Arena-Hard v0.1": "78",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1237,
    "Arena Elo (hard-en) - latest": 1237,
    "haiku_reward.K=500": 24.90234375,
    "llama_reward.K=500": 44.921875,
    "gpt4t_reward.K=500": -8.0078125,
    "haiku_reward.Creative Tasks.K=500": 33.00561797752809,
    "llama_reward.Creative Tasks.K=500": 42.95774647887324,
    "gpt4t_reward.Creative Tasks.K=500": -2.7777777777777777,
    "mixture_of_rewards.Creative Tasks.K=500": 24.39519555954119,
    "haiku_reward.Planning & Reasoning.K=500": 24.363057324840764,
    "llama_reward.Planning & Reasoning.K=500": 49.84,
    "gpt4t_reward.Planning & Reasoning.K=500": -9.365325077399381,
    "mixture_of_rewards.Planning & Reasoning.K=500": 21.6125774158138,
    "haiku_reward.Math & Data Analysis.K=500": 23.25102880658436,
    "llama_reward.Math & Data Analysis.K=500": 57.676348547717836,
    "gpt4t_reward.Math & Data Analysis.K=500": -17.28395061728395,
    "mixture_of_rewards.Math & Data Analysis.K=500": 21.21447557900608,
    "haiku_reward.Information/Advice seeking.K=500": 21.46529562982005,
    "llama_reward.Information/Advice seeking.K=500": 40.3598971722365,
    "gpt4t_reward.Information/Advice seeking.K=500": -4.797979797979798,
    "mixture_of_rewards.Information/Advice seeking.K=500": 19.009071001358915,
    "haiku_reward.Coding & Debugging.K=500": 25.0,
    "llama_reward.Coding & Debugging.K=500": 65.34391534391534,
    "gpt4t_reward.Coding & Debugging.K=500": -13.520408163265307,
    "mixture_of_rewards.Coding & Debugging.K=500": 25.607835726883348,
    "haiku_reward.task_macro.K=500": 24.74876445763461,
    "llama_reward.task_macro.K=500": 53.34842923078442,
    "gpt4t_reward.task_macro.K=500": -10.711261243260745,
    "mixture_of_rewards.K=500": 20.60546875,
    "task_macro_reward.K=500": 22.461977481719426,
    "WB_score.Creative Tasks": 57.571059431524546,
    "WB_score.Planning & Reasoning": 53.45291479820627,
    "WB_score.Math & Data Analysis": 45.79365079365079,
    "WB_score.Information/Advice seeking": 54.35643564356436,
    "WB_score.Coding & Debugging": 52.924528301886795,
    "WB_score": 53.28125,
    "WB_score.task_macro": 52.27753918256898,
    "Length": 3335.638671875,
    "Rank_ScoreMacro": 12,
    "Rank_TaskMacroReward.K": 9,
    "Rank_Avg": 10.5,
    "RewardScore_Avg": 37.3697583321442,
    "WB_Elo": 1208.302900834726
  },
  "claude-3-opus-20240229": {
    "Arena-Hard v0.1": "60.4",
    "AE2.0 LC": "40.5",
    "AE2.0": "29.1",
    "Arena Elo (hard-en) - 2024-07-16": 1230,
    "Arena Elo (hard-en) - latest": 1230,
    "haiku_reward.K=500": 27.9296875,
    "llama_reward.K=500": 43.06640625,
    "gpt4t_reward.K=500": -10.05859375,
    "haiku_reward.Creative Tasks.K=500": 27.873563218390807,
    "llama_reward.Creative Tasks.K=500": 33.33333333333333,
    "gpt4t_reward.Creative Tasks.K=500": -14.425770308123248,
    "mixture_of_rewards.Creative Tasks.K=500": 15.593708747866962,
    "haiku_reward.Planning & Reasoning.K=500": 28.34138486312399,
    "llama_reward.Planning & Reasoning.K=500": 49.35064935064935,
    "gpt4t_reward.Planning & Reasoning.K=500": -9.235668789808917,
    "mixture_of_rewards.Planning & Reasoning.K=500": 22.81878847465481,
    "haiku_reward.Math & Data Analysis.K=500": 35.36585365853659,
    "llama_reward.Math & Data Analysis.K=500": 66.53061224489795,
    "gpt4t_reward.Math & Data Analysis.K=500": -7.377049180327869,
    "mixture_of_rewards.Math & Data Analysis.K=500": 31.506472241035556,
    "haiku_reward.Information/Advice seeking.K=500": 24.935400516795866,
    "llama_reward.Information/Advice seeking.K=500": 39.58333333333333,
    "gpt4t_reward.Information/Advice seeking.K=500": -3.984575835475578,
    "mixture_of_rewards.Information/Advice seeking.K=500": 20.178052671551203,
    "haiku_reward.Coding & Debugging.K=500": 37.637362637362635,
    "llama_reward.Coding & Debugging.K=500": 65.93406593406593,
    "gpt4t_reward.Coding & Debugging.K=500": -16.756756756756758,
    "mixture_of_rewards.Coding & Debugging.K=500": 28.93822393822393,
    "haiku_reward.task_macro.K=500": 31.679498953881513,
    "llama_reward.task_macro.K=500": 54.10329958262289,
    "gpt4t_reward.task_macro.K=500": -10.540820661937529,
    "mixture_of_rewards.K=500": 20.3125,
    "task_macro_reward.K=500": 25.08065929152229,
    "WB_score.Creative Tasks": 53.0232558139535,
    "WB_score.Planning & Reasoning": 52.526158445440956,
    "WB_score.Math & Data Analysis": 46.74603174603174,
    "WB_score.Information/Advice seeking": 53.46534653465346,
    "WB_score.Coding & Debugging": 53.301886792452834,
    "WB_score": 52.109375,
    "WB_score.task_macro": 51.714047600287536,
    "Length": 2685.9794921875,
    "Rank_ScoreMacro": 13,
    "Rank_TaskMacroReward.K": 6,
    "Rank_Avg": 9.5,
    "RewardScore_Avg": 38.39735344590491,
    "WB_Elo": 1207.4751834070414
  },
  "Meta-Llama-3-70B-Instruct": {
    "Arena-Hard v0.1": "41.1",
    "AE2.0 LC": "34.4",
    "AE2.0": "33.2",
    "Arena Elo (hard-en) - 2024-07-16": 1212,
    "Arena Elo (hard-en) - latest": 1212,
    "haiku_reward.K=500": 23.264907135874875,
    "llama_reward.K=500": 44.28152492668622,
    "gpt4t_reward.K=500": -13.098729227761485,
    "haiku_reward.Creative Tasks.K=500": 26.231884057971016,
    "llama_reward.Creative Tasks.K=500": 40.0,
    "gpt4t_reward.Creative Tasks.K=500": -14.86111111111111,
    "mixture_of_rewards.Creative Tasks.K=500": 17.123590982286633,
    "haiku_reward.Planning & Reasoning.K=500": 25.44570502431118,
    "llama_reward.Planning & Reasoning.K=500": 50.163132137031,
    "gpt4t_reward.Planning & Reasoning.K=500": -13.36,
    "mixture_of_rewards.Planning & Reasoning.K=500": 20.74961238711406,
    "haiku_reward.Math & Data Analysis.K=500": 31.069958847736622,
    "llama_reward.Math & Data Analysis.K=500": 65.22633744855966,
    "gpt4t_reward.Math & Data Analysis.K=500": -10.950413223140496,
    "mixture_of_rewards.Math & Data Analysis.K=500": 28.448627691051925,
    "haiku_reward.Information/Advice seeking.K=500": 21.391752577319586,
    "llama_reward.Information/Advice seeking.K=500": 40.97938144329897,
    "gpt4t_reward.Information/Advice seeking.K=500": -8.269720101781171,
    "mixture_of_rewards.Information/Advice seeking.K=500": 18.03380463961246,
    "haiku_reward.Coding & Debugging.K=500": 27.09497206703911,
    "llama_reward.Coding & Debugging.K=500": 67.22222222222223,
    "gpt4t_reward.Coding & Debugging.K=500": -19.337016574585636,
    "mixture_of_rewards.Coding & Debugging.K=500": 24.99339257155857,
    "haiku_reward.task_macro.K=500": 26.50643403661046,
    "llama_reward.task_macro.K=500": 55.30369820633694,
    "gpt4t_reward.task_macro.K=500": -13.779900962792416,
    "mixture_of_rewards.K=500": 18.149234278266537,
    "task_macro_reward.K=500": 22.676743760051664,
    "WB_score.Creative Tasks": 54.30051813471502,
    "WB_score.Planning & Reasoning": 50.07473841554558,
    "WB_score.Math & Data Analysis": 42.063492063492056,
    "WB_score.Information/Advice seeking": 52.27722772277227,
    "WB_score.Coding & Debugging": 44.71698113207546,
    "WB_score": 49.579667644183765,
    "WB_score.task_macro": 47.770804496306326,
    "Length": 3046.6383186705766,
    "Rank_ScoreMacro": 18,
    "Rank_TaskMacroReward.K": 7,
    "Rank_Avg": 12.5,
    "RewardScore_Avg": 35.223774128178995,
    "WB_Elo": 1194.6486448820997
  },
  "Qwen1.5-72B-Chat-greedy": {
    "Arena-Hard v0.1": "36.1",
    "AE2.0 LC": "36.6",
    "AE2.0": "26.5",
    "Arena Elo (hard-en) - 2024-07-16": 1142,
    "Arena Elo (hard-en) - latest": 1142,
    "haiku_reward.K=500": 12.59765625,
    "llama_reward.K=500": 37.79296875,
    "gpt4t_reward.K=500": -21.77734375,
    "haiku_reward.Creative Tasks.K=500": 23.25905292479109,
    "llama_reward.Creative Tasks.K=500": 34.497206703910614,
    "gpt4t_reward.Creative Tasks.K=500": -15.435356200527705,
    "mixture_of_rewards.Creative Tasks.K=500": 14.10696780939133,
    "haiku_reward.Planning & Reasoning.K=500": 11.773940345368917,
    "llama_reward.Planning & Reasoning.K=500": 42.73301737756714,
    "gpt4t_reward.Planning & Reasoning.K=500": -21.658986175115206,
    "mixture_of_rewards.Planning & Reasoning.K=500": 10.949323849273616,
    "haiku_reward.Math & Data Analysis.K=500": -0.20242914979757085,
    "llama_reward.Math & Data Analysis.K=500": 51.016260162601625,
    "gpt4t_reward.Math & Data Analysis.K=500": -32.926829268292686,
    "mixture_of_rewards.Math & Data Analysis.K=500": 5.962333914837122,
    "haiku_reward.Information/Advice seeking.K=500": 10.841836734693878,
    "llama_reward.Information/Advice seeking.K=500": 33.37595907928389,
    "gpt4t_reward.Information/Advice seeking.K=500": -14.393939393939394,
    "mixture_of_rewards.Information/Advice seeking.K=500": 9.941285473346124,
    "haiku_reward.Coding & Debugging.K=500": 5.7591623036649215,
    "llama_reward.Coding & Debugging.K=500": 48.94736842105264,
    "gpt4t_reward.Coding & Debugging.K=500": -38.578680203045685,
    "mixture_of_rewards.Coding & Debugging.K=500": 5.375950173890625,
    "haiku_reward.task_macro.K=500": 8.7315480368233,
    "llama_reward.task_macro.K=500": 43.767855804693596,
    "gpt4t_reward.task_macro.K=500": -26.681483134044676,
    "mixture_of_rewards.K=500": 9.537760416666666,
    "task_macro_reward.K=500": 8.605973569157406,
    "WB_score.Creative Tasks": 50.362694300518136,
    "WB_score.Planning & Reasoning": 43.45345345345345,
    "WB_score.Math & Data Analysis": 29.800796812748995,
    "WB_score.Information/Advice seeking": 48.21782178217822,
    "WB_score.Coding & Debugging": 35.35545023696683,
    "WB_score": 43.46718903036239,
    "WB_score.task_macro": 39.927713665824655,
    "Length": 2392.364348677767,
    "Rank_ScoreMacro": 28,
    "Rank_TaskMacroReward.K": 20,
    "Rank_Avg": 24.0,
    "RewardScore_Avg": 24.26684361749103,
    "WB_Elo": 1150.1365337277027
  },
  "claude-3-sonnet-20240229": {
    "Arena-Hard v0.1": "46.8",
    "AE2.0 LC": "34.9",
    "AE2.0": "25.6",
    "Arena Elo (hard-en) - 2024-07-16": 1188,
    "Arena Elo (hard-en) - latest": 1188,
    "haiku_reward.K=500": 15.73802541544477,
    "llama_reward.K=500": 31.640625,
    "gpt4t_reward.K=500": -20.1171875,
    "haiku_reward.Creative Tasks.K=500": 11.647727272727272,
    "llama_reward.Creative Tasks.K=500": 18.71345029239766,
    "gpt4t_reward.Creative Tasks.K=500": -27.70083102493075,
    "mixture_of_rewards.Creative Tasks.K=500": 0.8867821800647278,
    "haiku_reward.Planning & Reasoning.K=500": 18.901453957996768,
    "llama_reward.Planning & Reasoning.K=500": 39.026402640264024,
    "gpt4t_reward.Planning & Reasoning.K=500": -18.174474959612276,
    "mixture_of_rewards.Planning & Reasoning.K=500": 13.251127212882837,
    "haiku_reward.Math & Data Analysis.K=500": 22.42798353909465,
    "llama_reward.Math & Data Analysis.K=500": 59.375,
    "gpt4t_reward.Math & Data Analysis.K=500": -22.899159663865547,
    "mixture_of_rewards.Math & Data Analysis.K=500": 19.634607958409703,
    "haiku_reward.Information/Advice seeking.K=500": 14.192708333333334,
    "llama_reward.Information/Advice seeking.K=500": 26.83246073298429,
    "gpt4t_reward.Information/Advice seeking.K=500": -12.176165803108809,
    "mixture_of_rewards.Information/Advice seeking.K=500": 9.616334421069604,
    "haiku_reward.Coding & Debugging.K=500": 18.994413407821227,
    "llama_reward.Coding & Debugging.K=500": 57.10227272727273,
    "gpt4t_reward.Coding & Debugging.K=500": -27.09497206703911,
    "mixture_of_rewards.Coding & Debugging.K=500": 16.333904689351616,
    "haiku_reward.task_macro.K=500": 18.161307922680166,
    "llama_reward.task_macro.K=500": 44.00356103270695,
    "gpt4t_reward.task_macro.K=500": -21.572317539363528,
    "mixture_of_rewards.K=500": 9.087154305148255,
    "task_macro_reward.K=500": 13.530850472007861,
    "WB_score.Creative Tasks": 46.304909560723516,
    "WB_score.Planning & Reasoning": 47.425149700598794,
    "WB_score.Math & Data Analysis": 40.63745019920319,
    "WB_score.Information/Advice seeking": 47.128712871287135,
    "WB_score.Coding & Debugging": 46.09523809523809,
    "WB_score": 45.24461839530332,
    "WB_score.task_macro": 45.48145776375293,
    "Length": 2670.243639921722,
    "Rank_ScoreMacro": 24,
    "Rank_TaskMacroReward.K": 14,
    "Rank_Avg": 19.0,
    "RewardScore_Avg": 29.506154117880396,
    "WB_Elo": 1180.9039586012009
  },
  "mistral-large-2402": {
    "Arena-Hard v0.1": "37.7",
    "AE2.0 LC": "32.7",
    "AE2.0": "21.4",
    "Arena Elo (hard-en) - 2024-07-16": 1158,
    "Arena Elo (hard-en) - latest": 1158,
    "haiku_reward.K=500": -2.587890625,
    "llama_reward.K=500": 23.75366568914956,
    "gpt4t_reward.K=500": -35.05859375,
    "haiku_reward.Creative Tasks.K=500": 10.458452722063036,
    "llama_reward.Creative Tasks.K=500": 19.653179190751445,
    "gpt4t_reward.Creative Tasks.K=500": -31.267217630853995,
    "mixture_of_rewards.Creative Tasks.K=500": -0.3851952393465048,
    "haiku_reward.Planning & Reasoning.K=500": -5.7507987220447285,
    "llama_reward.Planning & Reasoning.K=500": 23.9870340356564,
    "gpt4t_reward.Planning & Reasoning.K=500": -37.71653543307087,
    "mixture_of_rewards.Planning & Reasoning.K=500": -6.4934333731530645,
    "haiku_reward.Math & Data Analysis.K=500": -10.905349794238683,
    "llama_reward.Math & Data Analysis.K=500": 40.24896265560166,
    "gpt4t_reward.Math & Data Analysis.K=500": -45.02074688796681,
    "mixture_of_rewards.Math & Data Analysis.K=500": -5.225711342201277,
    "haiku_reward.Information/Advice seeking.K=500": -8.740359897172237,
    "llama_reward.Information/Advice seeking.K=500": 15.374677002583978,
    "gpt4t_reward.Information/Advice seeking.K=500": -29.64376590330789,
    "mixture_of_rewards.Information/Advice seeking.K=500": -7.669816265965383,
    "haiku_reward.Coding & Debugging.K=500": -10.638297872340425,
    "llama_reward.Coding & Debugging.K=500": 40.74074074074074,
    "gpt4t_reward.Coding & Debugging.K=500": -49.74226804123711,
    "mixture_of_rewards.Coding & Debugging.K=500": -6.546608390945598,
    "haiku_reward.task_macro.K=500": -6.887950336645848,
    "llama_reward.task_macro.K=500": 30.003427047034066,
    "gpt4t_reward.task_macro.K=500": -40.465407257633615,
    "mixture_of_rewards.K=500": -4.6309395619501466,
    "task_macro_reward.K=500": -5.783310182415132,
    "WB_score.Creative Tasks": 49.66408268733851,
    "WB_score.Planning & Reasoning": 41.79910044977511,
    "WB_score.Math & Data Analysis": 30.879999999999992,
    "WB_score.Information/Advice seeking": 46.13861386138615,
    "WB_score.Coding & Debugging": 33.74407582938389,
    "WB_score": 42.28739002932551,
    "WB_score.task_macro": 38.89367833445423,
    "Length": 2514.9814090019568,
    "Rank_ScoreMacro": 31,
    "Rank_TaskMacroReward.K": 40,
    "Rank_Avg": 35.5,
    "RewardScore_Avg": 16.55518407601955,
    "WB_Elo": 1158.021169549111
  },
  "claude-3-haiku-20240307": {
    "Arena-Hard v0.1": "41.5",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1170,
    "Arena Elo (hard-en) - latest": 1170,
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 22.021484375,
    "gpt4t_reward.K=500": -32.8125,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 7.566765578635016,
    "gpt4t_reward.Creative Tasks.K=500": -37.640449438202246,
    "mixture_of_rewards.Creative Tasks.K=500": -10.024561286522411,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 26.998368678629692,
    "gpt4t_reward.Planning & Reasoning.K=500": -33.06709265175719,
    "mixture_of_rewards.Planning & Reasoning.K=500": -2.0229079910425,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 41.11570247933884,
    "gpt4t_reward.Math & Data Analysis.K=500": -39.41908713692946,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.5655384474697934,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 21.502590673575128,
    "gpt4t_reward.Information/Advice seeking.K=500": -23.974358974358974,
    "mixture_of_rewards.Information/Advice seeking.K=500": -0.8239227669279489,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 45.0,
    "gpt4t_reward.Coding & Debugging.K=500": -40.21739130434783,
    "mixture_of_rewards.Coding & Debugging.K=500": 1.594202898550724,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 31.79452402571049,
    "gpt4t_reward.task_macro.K=500": -35.33172337514338,
    "mixture_of_rewards.K=500": -3.5970052083333335,
    "task_macro_reward.K=500": -1.1790664498109642,
    "WB_score.Creative Tasks": 42.94573643410853,
    "WB_score.Planning & Reasoning": 41.28550074738415,
    "WB_score.Math & Data Analysis": 31.428571428571423,
    "WB_score.Information/Advice seeking": 45.346534653465355,
    "WB_score.Coding & Debugging": 36.9811320754717,
    "WB_score": 40.25390625,
    "WB_score.task_macro": 38.893606666167265,
    "Length": 2601.029296875,
    "Rank_ScoreMacro": 32,
    "Rank_TaskMacroReward.K": 35,
    "Rank_Avg": 33.5,
    "RewardScore_Avg": 18.85727010817815,
    "WB_Elo": 1159.819595320082
  },
  "dbrx-instruct@together": {
    "Arena-Hard v0.1": "23.9",
    "AE2.0 LC": "25.4",
    "AE2.0": "18.4",
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": -14.111328125,
    "llama_reward.K=500": 13.232421875,
    "gpt4t_reward.K=500": -44.82421875,
    "haiku_reward.Creative Tasks.K=500": -7.857142857142857,
    "llama_reward.Creative Tasks.K=500": 2.7377521613832854,
    "gpt4t_reward.Creative Tasks.K=500": -43.71584699453552,
    "mixture_of_rewards.Creative Tasks.K=500": -16.278412563431697,
    "haiku_reward.Planning & Reasoning.K=500": -16.534181240063592,
    "llama_reward.Planning & Reasoning.K=500": 17.067307692307693,
    "gpt4t_reward.Planning & Reasoning.K=500": -47.492163009404386,
    "mixture_of_rewards.Planning & Reasoning.K=500": -15.653012185720096,
    "haiku_reward.Math & Data Analysis.K=500": -13.37448559670782,
    "llama_reward.Math & Data Analysis.K=500": 36.51452282157676,
    "gpt4t_reward.Math & Data Analysis.K=500": -53.11203319502075,
    "mixture_of_rewards.Math & Data Analysis.K=500": -9.990665323383936,
    "haiku_reward.Information/Advice seeking.K=500": -21.059431524547804,
    "llama_reward.Information/Advice seeking.K=500": 1.9329896907216495,
    "gpt4t_reward.Information/Advice seeking.K=500": -41.454081632653065,
    "mixture_of_rewards.Information/Advice seeking.K=500": -20.19350782215974,
    "haiku_reward.Coding & Debugging.K=500": -17.36842105263158,
    "llama_reward.Coding & Debugging.K=500": 33.86243386243386,
    "gpt4t_reward.Coding & Debugging.K=500": -56.44329896907217,
    "mixture_of_rewards.Coding & Debugging.K=500": -13.31642871975663,
    "haiku_reward.task_macro.K=500": -15.889659691486122,
    "llama_reward.task_macro.K=500": 21.6832248660498,
    "gpt4t_reward.task_macro.K=500": -49.67996745049978,
    "mixture_of_rewards.K=500": -15.234375,
    "task_macro_reward.K=500": -14.628800758645367,
    "WB_score.Creative Tasks": 42.32558139534884,
    "WB_score.Planning & Reasoning": 36.227544910179645,
    "WB_score.Math & Data Analysis": 24.523809523809526,
    "WB_score.Information/Advice seeking": 41.089108910891085,
    "WB_score.Coding & Debugging": 26.445497630331758,
    "WB_score": 35.5425219941349,
    "WB_score.task_macro": 32.598891595850844,
    "Length": 2576.5190615835777,
    "Rank_ScoreMacro": 39,
    "Rank_TaskMacroReward.K": 45,
    "Rank_Avg": 42.0,
    "RewardScore_Avg": 8.985045418602738,
    "WB_Elo": 1123.3353568518312
  },
  "Mixtral-8x7B-Instruct-v0.1": {
    "Arena-Hard v0.1": "23.4",
    "AE2.0 LC": "23.7",
    "AE2.0": "18.3",
    "Arena Elo (hard-en) - 2024-07-16": 1114,
    "Arena Elo (hard-en) - latest": 1114,
    "haiku_reward.K=500": -11.71875,
    "llama_reward.K=500": 14.794921875,
    "gpt4t_reward.K=500": -40.869140625,
    "haiku_reward.Creative Tasks.K=500": -3.7142857142857144,
    "llama_reward.Creative Tasks.K=500": 6.976744186046512,
    "gpt4t_reward.Creative Tasks.K=500": -39.42307692307692,
    "mixture_of_rewards.Creative Tasks.K=500": -12.053539483772042,
    "haiku_reward.Planning & Reasoning.K=500": -16.479099678456592,
    "llama_reward.Planning & Reasoning.K=500": 16.612377850162865,
    "gpt4t_reward.Planning & Reasoning.K=500": -43.22169059011164,
    "mixture_of_rewards.Planning & Reasoning.K=500": -14.362804139468457,
    "haiku_reward.Math & Data Analysis.K=500": -20.416666666666668,
    "llama_reward.Math & Data Analysis.K=500": 31.171548117154813,
    "gpt4t_reward.Math & Data Analysis.K=500": -51.68067226890757,
    "mixture_of_rewards.Math & Data Analysis.K=500": -13.641930272806476,
    "haiku_reward.Information/Advice seeking.K=500": -11.11111111111111,
    "llama_reward.Information/Advice seeking.K=500": 12.046632124352332,
    "gpt4t_reward.Information/Advice seeking.K=500": -34.35897435897436,
    "mixture_of_rewards.Information/Advice seeking.K=500": -11.141151115244378,
    "haiku_reward.Coding & Debugging.K=500": -24.462365591397848,
    "llama_reward.Coding & Debugging.K=500": 26.50273224043716,
    "gpt4t_reward.Coding & Debugging.K=500": -54.25531914893617,
    "mixture_of_rewards.Coding & Debugging.K=500": -17.404984166632286,
    "haiku_reward.task_macro.K=500": -17.217678830412822,
    "llama_reward.task_macro.K=500": 20.54500671930365,
    "gpt4t_reward.task_macro.K=500": -46.1068849838919,
    "mixture_of_rewards.K=500": -12.59765625,
    "task_macro_reward.K=500": -14.259852365000357,
    "WB_score.Creative Tasks": 42.753246753246756,
    "WB_score.Planning & Reasoning": 34.586466165413526,
    "WB_score.Math & Data Analysis": 22.142857142857135,
    "WB_score.Information/Advice seeking": 41.935483870967744,
    "WB_score.Coding & Debugging": 25.023696682464447,
    "WB_score": 35.0293542074364,
    "WB_score.task_macro": 31.47027304895869,
    "Length": 2653.5813725490198,
    "Rank_ScoreMacro": 41,
    "Rank_TaskMacroReward.K": 44,
    "Rank_Avg": 42.5,
    "RewardScore_Avg": 8.605210341979166,
    "WB_Elo": 1122.7834564499847
  },
  "Starling-LM-7B-beta": {
    "Arena-Hard v0.1": "23",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1113,
    "Arena Elo (hard-en) - latest": 1113,
    "haiku_reward.K=500": -7.421875,
    "llama_reward.K=500": 17.578125,
    "gpt4t_reward.K=500": -38.232421875,
    "haiku_reward.Creative Tasks.K=500": 4.353932584269663,
    "llama_reward.Creative Tasks.K=500": 16.807909604519775,
    "gpt4t_reward.Creative Tasks.K=500": -29.708222811671085,
    "mixture_of_rewards.Creative Tasks.K=500": -2.8487935409605485,
    "haiku_reward.Planning & Reasoning.K=500": -10.651828298887123,
    "llama_reward.Planning & Reasoning.K=500": 18.660287081339714,
    "gpt4t_reward.Planning & Reasoning.K=500": -41.14906832298137,
    "mixture_of_rewards.Planning & Reasoning.K=500": -11.046869846842926,
    "haiku_reward.Math & Data Analysis.K=500": -22.016460905349795,
    "llama_reward.Math & Data Analysis.K=500": 21.074380165289256,
    "gpt4t_reward.Math & Data Analysis.K=500": -57.02479338842975,
    "mixture_of_rewards.Math & Data Analysis.K=500": -19.32229137616343,
    "haiku_reward.Information/Advice seeking.K=500": -7.583547557840617,
    "llama_reward.Information/Advice seeking.K=500": 17.994858611825194,
    "gpt4t_reward.Information/Advice seeking.K=500": -30.710659898477154,
    "mixture_of_rewards.Information/Advice seeking.K=500": -6.766449614830859,
    "haiku_reward.Coding & Debugging.K=500": -19.148936170212767,
    "llama_reward.Coding & Debugging.K=500": 29.100529100529098,
    "gpt4t_reward.Coding & Debugging.K=500": -53.626943005181346,
    "mixture_of_rewards.Coding & Debugging.K=500": -14.558450024955006,
    "haiku_reward.task_macro.K=500": -13.216444393256902,
    "llama_reward.task_macro.K=500": 21.61589455868506,
    "gpt4t_reward.task_macro.K=500": -44.92250818491086,
    "mixture_of_rewards.K=500": -9.358723958333334,
    "task_macro_reward.K=500": -12.174352673160902,
    "WB_score.Creative Tasks": 43.79220779220779,
    "WB_score.Planning & Reasoning": 34.050822122571006,
    "WB_score.Math & Data Analysis": 16.984126984126977,
    "WB_score.Information/Advice seeking": 41.88118811881188,
    "WB_score.Coding & Debugging": 24.36018957345972,
    "WB_score": 34.17399804496579,
    "WB_score.task_macro": 30.16944980829014,
    "Length": 2797.807240704501,
    "Rank_ScoreMacro": 44,
    "Rank_TaskMacroReward.K": 43,
    "Rank_Avg": 43.5,
    "RewardScore_Avg": 8.997548567564618,
    "WB_Elo": 1119.3332864397855
  },
  "command-r": {
    "Arena-Hard v0.1": "17",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1106,
    "Arena Elo (hard-en) - latest": 1106,
    "haiku_reward.K=500": -14.6484375,
    "llama_reward.K=500": 11.767578125,
    "gpt4t_reward.K=500": -39.111328125,
    "haiku_reward.Creative Tasks.K=500": 0.7575757575757576,
    "llama_reward.Creative Tasks.K=500": 8.950617283950617,
    "gpt4t_reward.Creative Tasks.K=500": -34.42136498516321,
    "mixture_of_rewards.Creative Tasks.K=500": -8.237723981212278,
    "haiku_reward.Planning & Reasoning.K=500": -17.868852459016395,
    "llama_reward.Planning & Reasoning.K=500": 14.710743801652892,
    "gpt4t_reward.Planning & Reasoning.K=500": -44.951140065146575,
    "mixture_of_rewards.Planning & Reasoning.K=500": -16.03641624083669,
    "haiku_reward.Math & Data Analysis.K=500": -35.26970954356847,
    "llama_reward.Math & Data Analysis.K=500": 18.75,
    "gpt4t_reward.Math & Data Analysis.K=500": -58.82352941176471,
    "mixture_of_rewards.Math & Data Analysis.K=500": -25.11441298511106,
    "haiku_reward.Information/Advice seeking.K=500": -8.638743455497382,
    "llama_reward.Information/Advice seeking.K=500": 13.35978835978836,
    "gpt4t_reward.Information/Advice seeking.K=500": -30.183727034120732,
    "mixture_of_rewards.Information/Advice seeking.K=500": -8.487560709943251,
    "haiku_reward.Coding & Debugging.K=500": -34.34065934065934,
    "llama_reward.Coding & Debugging.K=500": 18.30601092896175,
    "gpt4t_reward.Coding & Debugging.K=500": -62.77173913043478,
    "mixture_of_rewards.Coding & Debugging.K=500": -26.268795847377458,
    "haiku_reward.task_macro.K=500": -22.44881452757859,
    "llama_reward.task_macro.K=500": 15.687598594754713,
    "gpt4t_reward.task_macro.K=500": -49.12118024724496,
    "mixture_of_rewards.K=500": -13.997395833333334,
    "task_macro_reward.K=500": -18.627465393356278,
    "WB_score.Creative Tasks": 47.44186046511628,
    "WB_score.Planning & Reasoning": 34.61883408071749,
    "WB_score.Math & Data Analysis": 16.031746031746028,
    "WB_score.Information/Advice seeking": 44.10891089108912,
    "WB_score.Coding & Debugging": 19.33962264150944,
    "WB_score": 35.05859375,
    "WB_score.task_macro": 29.533143228506248,
    "Length": 2919.423828125,
    "Rank_ScoreMacro": 47,
    "Rank_TaskMacroReward.K": 48,
    "Rank_Avg": 47.5,
    "RewardScore_Avg": 5.452838917574985,
    "WB_Elo": 1119.8497539885705
  },
  "command-r-plus": {
    "Arena-Hard v0.1": "33.1",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1155,
    "Arena Elo (hard-en) - latest": 1155,
    "haiku_reward.K=500": 2.34375,
    "llama_reward.K=500": 25.146484375,
    "gpt4t_reward.K=500": -29.638671875,
    "haiku_reward.Creative Tasks.K=500": 17.87974683544304,
    "llama_reward.Creative Tasks.K=500": 27.287581699346404,
    "gpt4t_reward.Creative Tasks.K=500": -21.69811320754717,
    "mixture_of_rewards.Creative Tasks.K=500": 7.823071775747426,
    "haiku_reward.Planning & Reasoning.K=500": 1.3468013468013467,
    "llama_reward.Planning & Reasoning.K=500": 30.40885860306644,
    "gpt4t_reward.Planning & Reasoning.K=500": -32.209106239460375,
    "mixture_of_rewards.Planning & Reasoning.K=500": -0.15114876319752923,
    "haiku_reward.Math & Data Analysis.K=500": -11.570247933884298,
    "llama_reward.Math & Data Analysis.K=500": 36.570247933884296,
    "gpt4t_reward.Math & Data Analysis.K=500": -46.666666666666664,
    "mixture_of_rewards.Math & Data Analysis.K=500": -7.222222222222221,
    "haiku_reward.Information/Advice seeking.K=500": 7.220708446866484,
    "llama_reward.Information/Advice seeking.K=500": 25.068493150684933,
    "gpt4t_reward.Information/Advice seeking.K=500": -22.404371584699454,
    "mixture_of_rewards.Information/Advice seeking.K=500": 3.294943337617321,
    "haiku_reward.Coding & Debugging.K=500": -13.764044943820226,
    "llama_reward.Coding & Debugging.K=500": 32.10227272727273,
    "gpt4t_reward.Coding & Debugging.K=500": -56.70391061452514,
    "mixture_of_rewards.Coding & Debugging.K=500": -12.78856094369088,
    "haiku_reward.task_macro.K=500": -2.681346879428739,
    "llama_reward.task_macro.K=500": 30.97985743357793,
    "gpt4t_reward.task_macro.K=500": -39.04426800556773,
    "mixture_of_rewards.K=500": -0.7161458333333334,
    "task_macro_reward.K=500": -3.581919150472847,
    "WB_score.Creative Tasks": 52.55813953488372,
    "WB_score.Planning & Reasoning": 41.949025487256364,
    "WB_score.Math & Data Analysis": 23.492063492063497,
    "WB_score.Information/Advice seeking": 49.15841584158416,
    "WB_score.Coding & Debugging": 28.436018957345972,
    "WB_score": 41.565557729941304,
    "WB_score.task_macro": 36.76236856767293,
    "Length": 3293.812133072407,
    "Rank_ScoreMacro": 36,
    "Rank_TaskMacroReward.K": 37,
    "Rank_Avg": 36.5,
    "RewardScore_Avg": 16.59022470860004,
    "WB_Elo": 1151.2063636170662
  },
  "Meta-Llama-3-8B-Instruct": {
    "Arena-Hard v0.1": "20.6",
    "AE2.0 LC": "22.9",
    "AE2.0": "22.6",
    "Arena Elo (hard-en) - 2024-07-16": 1144,
    "Arena Elo (hard-en) - latest": 1144,
    "haiku_reward.K=500": -11.962890625,
    "llama_reward.K=500": 14.2578125,
    "gpt4t_reward.K=500": -41.064453125,
    "haiku_reward.Creative Tasks.K=500": -0.8547008547008548,
    "llama_reward.Creative Tasks.K=500": 8.309037900874635,
    "gpt4t_reward.Creative Tasks.K=500": -38.9344262295082,
    "mixture_of_rewards.Creative Tasks.K=500": -10.493363061111472,
    "haiku_reward.Planning & Reasoning.K=500": -14.492753623188406,
    "llama_reward.Planning & Reasoning.K=500": 18.91233766233766,
    "gpt4t_reward.Planning & Reasoning.K=500": -42.117834394904456,
    "mixture_of_rewards.Planning & Reasoning.K=500": -12.566083451918402,
    "haiku_reward.Math & Data Analysis.K=500": -25.206611570247933,
    "llama_reward.Math & Data Analysis.K=500": 30.70539419087137,
    "gpt4t_reward.Math & Data Analysis.K=500": -52.719665271966534,
    "mixture_of_rewards.Math & Data Analysis.K=500": -15.740294217114366,
    "haiku_reward.Information/Advice seeking.K=500": -10.9375,
    "llama_reward.Information/Advice seeking.K=500": 11.518324607329843,
    "gpt4t_reward.Information/Advice seeking.K=500": -34.02597402597402,
    "mixture_of_rewards.Information/Advice seeking.K=500": -11.14838313954806,
    "haiku_reward.Coding & Debugging.K=500": -27.808988764044944,
    "llama_reward.Coding & Debugging.K=500": 23.743016759776538,
    "gpt4t_reward.Coding & Debugging.K=500": -57.88043478260869,
    "mixture_of_rewards.Coding & Debugging.K=500": -20.648802262292364,
    "haiku_reward.task_macro.K=500": -18.25563473297685,
    "llama_reward.task_macro.K=500": 20.382705184094487,
    "gpt4t_reward.task_macro.K=500": -46.885093763808975,
    "mixture_of_rewards.K=500": -12.923177083333334,
    "task_macro_reward.K=500": -14.919341104230446,
    "WB_score.Creative Tasks": 43.56589147286822,
    "WB_score.Planning & Reasoning": 34.401197604790426,
    "WB_score.Math & Data Analysis": 16.972111553784863,
    "WB_score.Information/Advice seeking": 39.30693069306932,
    "WB_score.Coding & Debugging": 21.9811320754717,
    "WB_score": 33.176930596285445,
    "WB_score.task_macro": 29.20277208638918,
    "Length": 2975.1876832844573,
    "Rank_ScoreMacro": 48,
    "Rank_TaskMacroReward.K": 46,
    "Rank_Avg": 47.0,
    "RewardScore_Avg": 7.141715491079368,
    "WB_Elo": 1134.2361846879544
  },
  "tulu-2-dpo-70b": {
    "Arena-Hard v0.1": "15",
    "AE2.0 LC": "21.2",
    "AE2.0": "16",
    "Arena Elo (hard-en) - 2024-07-16": 1101,
    "Arena Elo (hard-en) - latest": 1101,
    "haiku_reward.K=500": -17.578125,
    "llama_reward.K=500": 8.49609375,
    "gpt4t_reward.K=500": -46.630859375,
    "haiku_reward.Creative Tasks.K=500": -4.302670623145401,
    "llama_reward.Creative Tasks.K=500": 8.333333333333332,
    "gpt4t_reward.Creative Tasks.K=500": -44.49152542372881,
    "mixture_of_rewards.Creative Tasks.K=500": -13.486954237846959,
    "haiku_reward.Planning & Reasoning.K=500": -23.534201954397393,
    "llama_reward.Planning & Reasoning.K=500": 10.457516339869281,
    "gpt4t_reward.Planning & Reasoning.K=500": -50.641025641025635,
    "mixture_of_rewards.Planning & Reasoning.K=500": -21.23923708518458,
    "haiku_reward.Math & Data Analysis.K=500": -35.41666666666667,
    "llama_reward.Math & Data Analysis.K=500": 19.747899159663866,
    "gpt4t_reward.Math & Data Analysis.K=500": -63.13559322033898,
    "mixture_of_rewards.Math & Data Analysis.K=500": -26.268120242447264,
    "haiku_reward.Information/Advice seeking.K=500": -16.710875331564985,
    "llama_reward.Information/Advice seeking.K=500": -1.3297872340425532,
    "gpt4t_reward.Information/Advice seeking.K=500": -41.0761154855643,
    "mixture_of_rewards.Information/Advice seeking.K=500": -19.705592683723946,
    "haiku_reward.Coding & Debugging.K=500": -35.31073446327684,
    "llama_reward.Coding & Debugging.K=500": 21.22905027932961,
    "gpt4t_reward.Coding & Debugging.K=500": -63.934426229508205,
    "mixture_of_rewards.Coding & Debugging.K=500": -26.005370137818478,
    "haiku_reward.task_macro.K=500": -26.033121894527554,
    "llama_reward.task_macro.K=500": 13.163249194694155,
    "gpt4t_reward.task_macro.K=500": -54.612159449377664,
    "mixture_of_rewards.K=500": -18.570963541666668,
    "task_macro_reward.K=500": -22.49401071640369,
    "WB_score.Creative Tasks": 42.7012987012987,
    "WB_score.Planning & Reasoning": 32.30538922155688,
    "WB_score.Math & Data Analysis": 14.841269841269842,
    "WB_score.Information/Advice seeking": 40.69306930693068,
    "WB_score.Coding & Debugging": 20.663507109004744,
    "WB_score": 32.82502443792767,
    "WB_score.task_macro": 27.983756123225106,
    "Length": 2908.0714285714284,
    "Rank_ScoreMacro": 49,
    "Rank_TaskMacroReward.K": 50,
    "Rank_Avg": 49.5,
    "RewardScore_Avg": 2.7448727034107083,
    "WB_Elo": 1114.0029936423298
  },
  "Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1046,
    "Arena Elo (hard-en) - latest": 1046,
    "haiku_reward.K=500": -16.568914956011728,
    "llama_reward.K=500": 7.722385141739981,
    "gpt4t_reward.K=500": -46.676441837732156,
    "haiku_reward.Creative Tasks.K=500": -12.244897959183673,
    "llama_reward.Creative Tasks.K=500": -4.105571847507331,
    "gpt4t_reward.Creative Tasks.K=500": -49.85994397759104,
    "mixture_of_rewards.Creative Tasks.K=500": -22.070137928094013,
    "haiku_reward.Planning & Reasoning.K=500": -19.884488448844884,
    "llama_reward.Planning & Reasoning.K=500": 11.185308848080133,
    "gpt4t_reward.Planning & Reasoning.K=500": -49.26108374384236,
    "mixture_of_rewards.Planning & Reasoning.K=500": -19.320087781535705,
    "haiku_reward.Math & Data Analysis.K=500": -19.874476987447697,
    "llama_reward.Math & Data Analysis.K=500": 27.848101265822784,
    "gpt4t_reward.Math & Data Analysis.K=500": -53.404255319148945,
    "mixture_of_rewards.Math & Data Analysis.K=500": -15.143543680257954,
    "haiku_reward.Information/Advice seeking.K=500": -19.444444444444446,
    "llama_reward.Information/Advice seeking.K=500": 1.4627659574468086,
    "gpt4t_reward.Information/Advice seeking.K=500": -44.576719576719576,
    "mixture_of_rewards.Information/Advice seeking.K=500": -20.852799354572404,
    "haiku_reward.Coding & Debugging.K=500": -20.50561797752809,
    "llama_reward.Coding & Debugging.K=500": 21.142857142857142,
    "gpt4t_reward.Coding & Debugging.K=500": -60.33519553072626,
    "mixture_of_rewards.Coding & Debugging.K=500": -19.899318788465735,
    "haiku_reward.task_macro.K=500": -19.172187859650332,
    "llama_reward.task_macro.K=500": 14.168967852384382,
    "gpt4t_reward.task_macro.K=500": -52.37097180709366,
    "mixture_of_rewards.K=500": -18.507657217334636,
    "task_macro_reward.K=500": -19.12473060478654,
    "WB_score.Creative Tasks": 37.92207792207792,
    "WB_score.Planning & Reasoning": 34.24287856071963,
    "WB_score.Math & Data Analysis": 21.752988047808763,
    "WB_score.Information/Advice seeking": 39.75247524752476,
    "WB_score.Coding & Debugging": 26.037735849056602,
    "WB_score": 33.22233104799217,
    "WB_score.task_macro": 30.711400306676122,
    "Length": 2874.541625857003,
    "Rank_ScoreMacro": 42,
    "Rank_TaskMacroReward.K": 49,
    "Rank_Avg": 45.5,
    "RewardScore_Avg": 5.793334850944792,
    "WB_Elo": 1080.5355552806532
  },
  "Mistral-7B-Instruct-v0.2": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "17.1",
    "AE2.0": "14.7",
    "Arena Elo (hard-en) - 2024-07-16": 1072,
    "Arena Elo (hard-en) - latest": 1072,
    "haiku_reward.K=500": -19.677734375,
    "llama_reward.K=500": 8.447265625,
    "gpt4t_reward.K=500": -47.16796875,
    "haiku_reward.Creative Tasks.K=500": -4.034582132564841,
    "llama_reward.Creative Tasks.K=500": 7.060518731988473,
    "gpt4t_reward.Creative Tasks.K=500": -41.07142857142857,
    "mixture_of_rewards.Creative Tasks.K=500": -12.681830657334979,
    "haiku_reward.Planning & Reasoning.K=500": -26.537216828478964,
    "llama_reward.Planning & Reasoning.K=500": 9.477124183006536,
    "gpt4t_reward.Planning & Reasoning.K=500": -51.433121019108285,
    "mixture_of_rewards.Planning & Reasoning.K=500": -22.8310712215269,
    "haiku_reward.Math & Data Analysis.K=500": -41.73728813559322,
    "llama_reward.Math & Data Analysis.K=500": 11.538461538461538,
    "gpt4t_reward.Math & Data Analysis.K=500": -64.59227467811158,
    "mixture_of_rewards.Math & Data Analysis.K=500": -31.597033758414415,
    "haiku_reward.Information/Advice seeking.K=500": -17.10182767624021,
    "llama_reward.Information/Advice seeking.K=500": 6.824146981627297,
    "gpt4t_reward.Information/Advice seeking.K=500": -39.453125,
    "mixture_of_rewards.Information/Advice seeking.K=500": -16.576935231537636,
    "haiku_reward.Coding & Debugging.K=500": -35.714285714285715,
    "llama_reward.Coding & Debugging.K=500": 20.32967032967033,
    "gpt4t_reward.Coding & Debugging.K=500": -64.55026455026454,
    "mixture_of_rewards.Coding & Debugging.K=500": -26.64495997829331,
    "haiku_reward.task_macro.K=500": -28.293753292107716,
    "llama_reward.task_macro.K=500": 12.09375248032049,
    "gpt4t_reward.task_macro.K=500": -54.6730662474825,
    "mixture_of_rewards.K=500": -19.466145833333332,
    "task_macro_reward.K=500": -23.624355686423243,
    "WB_score.Creative Tasks": 42.072538860103634,
    "WB_score.Planning & Reasoning": 30.059880239520957,
    "WB_score.Math & Data Analysis": 10.079365079365079,
    "WB_score.Information/Advice seeking": 40.099255583126556,
    "WB_score.Coding & Debugging": 18.396226415094343,
    "WB_score": 30.694037145650057,
    "WB_score.task_macro": 25.633728318953878,
    "Length": 2832.3440860215055,
    "Rank_ScoreMacro": 51,
    "Rank_TaskMacroReward.K": 54,
    "Rank_Avg": 52.5,
    "RewardScore_Avg": 1.0046863162653175,
    "WB_Elo": 1095.8096850594482
  },
  "gpt-3.5-turbo-0125": {
    "Arena-Hard v0.1": "23.3",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1107,
    "Arena Elo (hard-en) - latest": 1107,
    "haiku_reward.K=500": -20.99609375,
    "llama_reward.K=500": 5.517578125,
    "gpt4t_reward.K=500": -52.197265625,
    "haiku_reward.Creative Tasks.K=500": -11.064425770308123,
    "llama_reward.Creative Tasks.K=500": 0.5633802816901409,
    "gpt4t_reward.Creative Tasks.K=500": -48.27127659574468,
    "mixture_of_rewards.Creative Tasks.K=500": -19.590774028120887,
    "haiku_reward.Planning & Reasoning.K=500": -24.25431711145997,
    "llama_reward.Planning & Reasoning.K=500": 10.189573459715639,
    "gpt4t_reward.Planning & Reasoning.K=500": -51.54559505409583,
    "mixture_of_rewards.Planning & Reasoning.K=500": -21.870112901946715,
    "haiku_reward.Math & Data Analysis.K=500": -30.364372469635626,
    "llama_reward.Math & Data Analysis.K=500": 20.0,
    "gpt4t_reward.Math & Data Analysis.K=500": -58.77551020408164,
    "mixture_of_rewards.Math & Data Analysis.K=500": -23.046627557905754,
    "haiku_reward.Information/Advice seeking.K=500": -25.892857142857146,
    "llama_reward.Information/Advice seeking.K=500": -4.209183673469387,
    "gpt4t_reward.Information/Advice seeking.K=500": -51.385390428211586,
    "mixture_of_rewards.Information/Advice seeking.K=500": -27.162477081512705,
    "haiku_reward.Coding & Debugging.K=500": -26.17801047120419,
    "llama_reward.Coding & Debugging.K=500": 24.86910994764398,
    "gpt4t_reward.Coding & Debugging.K=500": -64.64646464646465,
    "mixture_of_rewards.Coding & Debugging.K=500": -21.98512172334162,
    "haiku_reward.task_macro.K=500": -24.91718688216058,
    "llama_reward.task_macro.K=500": 12.831190872619485,
    "gpt4t_reward.task_macro.K=500": -56.14531914711859,
    "mixture_of_rewards.K=500": -22.55859375,
    "task_macro_reward.K=500": -22.743771718886563,
    "WB_score.Creative Tasks": 37.41602067183463,
    "WB_score.Planning & Reasoning": 33.3931240657698,
    "WB_score.Math & Data Analysis": 21.58730158730158,
    "WB_score.Information/Advice seeking": 36.485148514851474,
    "WB_score.Coding & Debugging": 26.54028436018958,
    "WB_score": 32.27761485826002,
    "WB_score.task_macro": 30.01598607195931,
    "Length": 1844.13880742913,
    "Rank_ScoreMacro": 45,
    "Rank_TaskMacroReward.K": 51,
    "Rank_Avg": 48.0,
    "RewardScore_Avg": 3.636107176536374,
    "WB_Elo": 1124.5088476993683
  },
  "Qwen1.5-7B-Chat@together": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "14.7",
    "AE2.0": "11.8",
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": -20.401174168297455,
    "llama_reward.K=500": 3.0791788856304985,
    "gpt4t_reward.K=500": -45.8455522971652,
    "haiku_reward.Creative Tasks.K=500": -2.9494382022471908,
    "llama_reward.Creative Tasks.K=500": 8.169014084507042,
    "gpt4t_reward.Creative Tasks.K=500": -36.60477453580902,
    "mixture_of_rewards.Creative Tasks.K=500": -10.461732884516389,
    "haiku_reward.Planning & Reasoning.K=500": -23.56230031948882,
    "llama_reward.Planning & Reasoning.K=500": 6.230031948881789,
    "gpt4t_reward.Planning & Reasoning.K=500": -46.411856474258975,
    "mixture_of_rewards.Planning & Reasoning.K=500": -21.248041614955337,
    "haiku_reward.Math & Data Analysis.K=500": -35.33057851239669,
    "llama_reward.Math & Data Analysis.K=500": 7.43801652892562,
    "gpt4t_reward.Math & Data Analysis.K=500": -59.09090909090909,
    "mixture_of_rewards.Math & Data Analysis.K=500": -28.994490358126722,
    "haiku_reward.Information/Advice seeking.K=500": -19.743589743589745,
    "llama_reward.Information/Advice seeking.K=500": -0.2564102564102564,
    "gpt4t_reward.Information/Advice seeking.K=500": -38.51010101010101,
    "mixture_of_rewards.Information/Advice seeking.K=500": -19.503367003367003,
    "haiku_reward.Coding & Debugging.K=500": -33.42391304347826,
    "llama_reward.Coding & Debugging.K=500": 7.258064516129033,
    "gpt4t_reward.Coding & Debugging.K=500": -63.61256544502618,
    "mixture_of_rewards.Coding & Debugging.K=500": -29.9261379907918,
    "haiku_reward.task_macro.K=500": -25.862264552615038,
    "llama_reward.task_macro.K=500": 5.93480767581789,
    "gpt4t_reward.task_macro.K=500": -51.327663055893844,
    "mixture_of_rewards.K=500": -21.055849193277385,
    "task_macro_reward.K=500": -23.751706644230328,
    "WB_score.Creative Tasks": 38.29457364341085,
    "WB_score.Planning & Reasoning": 28.878923766816147,
    "WB_score.Math & Data Analysis": 11.904761904761898,
    "WB_score.Information/Advice seeking": 34.00990099009901,
    "WB_score.Coding & Debugging": 14.88151658767773,
    "WB_score": 27.370478983382203,
    "WB_score.task_macro": 23.42316313940188,
    "Length": 2519.4203323558163,
    "Rank_ScoreMacro": 54,
    "Rank_TaskMacroReward.K": 55,
    "Rank_Avg": 54.5,
    "RewardScore_Avg": -0.16427175241422454,
    "WB_Elo": 1080.6354917293063
  },
  "Llama-2-70b-chat-hf": {
    "Arena-Hard v0.1": "11.6",
    "AE2.0 LC": "14.7",
    "AE2.0": "13.9",
    "Arena Elo (hard-en) - 2024-07-16": 1071,
    "Arena Elo (hard-en) - latest": 1071,
    "haiku_reward.K=500": -24.975562072336267,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": -50.146484375,
    "haiku_reward.Creative Tasks.K=500": -13.501483679525222,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": -48.16901408450705,
    "mixture_of_rewards.Creative Tasks.K=500": -20.556832588010757,
    "haiku_reward.Planning & Reasoning.K=500": -30.637254901960787,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": -54.99194847020934,
    "mixture_of_rewards.Planning & Reasoning.K=500": -28.543067790723374,
    "haiku_reward.Math & Data Analysis.K=500": -49.5850622406639,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": -69.79166666666666,
    "mixture_of_rewards.Math & Data Analysis.K=500": -39.792242969110184,
    "haiku_reward.Information/Advice seeking.K=500": -16.233766233766232,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": -39.35897435897436,
    "mixture_of_rewards.Information/Advice seeking.K=500": -18.53091353091353,
    "haiku_reward.Coding & Debugging.K=500": -54.166666666666664,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": -72.52747252747253,
    "mixture_of_rewards.Coding & Debugging.K=500": -42.231379731379725,
    "haiku_reward.task_macro.K=500": -36.74021699295484,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": -59.53572225794805,
    "mixture_of_rewards.K=500": -25.040682149112087,
    "task_macro_reward.K=500": -32.091979750300965,
    "WB_score.Creative Tasks": 40.0,
    "WB_score.Planning & Reasoning": 26.846846846846848,
    "WB_score.Math & Data Analysis": 4.176706827309236,
    "WB_score.Information/Advice seeking": 38.30845771144279,
    "WB_score.Coding & Debugging": 9.333333333333336,
    "WB_score": 26.9140625,
    "WB_score.task_macro": 20.659636912866645,
    "Length": 3138.3179587831205,
    "Rank_ScoreMacro": 58,
    "Rank_TaskMacroReward.K": 58,
    "Rank_Avg": 58.0,
    "RewardScore_Avg": -5.71617141871716,
    "WB_Elo": 1088.1354760938955
  },
  "Llama-2-7b-chat-hf": {
    "Arena-Hard v0.1": "4.6",
    "AE2.0 LC": "5.4",
    "AE2.0": "5",
    "Arena Elo (hard-en) - 2024-07-16": 1012,
    "Arena Elo (hard-en) - latest": 1012,
    "haiku_reward.K=500": -41.98435972629521,
    "llama_reward.K=500": -21.2890625,
    "gpt4t_reward.K=500": -63.330078125,
    "haiku_reward.Creative Tasks.K=500": -29.21511627906977,
    "llama_reward.Creative Tasks.K=500": -17.67241379310345,
    "gpt4t_reward.Creative Tasks.K=500": -61.47540983606557,
    "mixture_of_rewards.Creative Tasks.K=500": -36.12097996941293,
    "haiku_reward.Planning & Reasoning.K=500": -50.0,
    "llama_reward.Planning & Reasoning.K=500": -23.471074380165287,
    "gpt4t_reward.Planning & Reasoning.K=500": -69.55810147299509,
    "mixture_of_rewards.Planning & Reasoning.K=500": -47.67639195105346,
    "haiku_reward.Math & Data Analysis.K=500": -63.40425531914894,
    "llama_reward.Math & Data Analysis.K=500": -28.15126050420168,
    "gpt4t_reward.Math & Data Analysis.K=500": -79.91452991452992,
    "mixture_of_rewards.Math & Data Analysis.K=500": -57.156681912626844,
    "haiku_reward.Information/Advice seeking.K=500": -39.501312335958005,
    "llama_reward.Information/Advice seeking.K=500": -15.885416666666666,
    "gpt4t_reward.Information/Advice seeking.K=500": -57.235142118863045,
    "mixture_of_rewards.Information/Advice seeking.K=500": -37.540623707162574,
    "haiku_reward.Coding & Debugging.K=500": -71.30681818181817,
    "llama_reward.Coding & Debugging.K=500": -40.78212290502793,
    "gpt4t_reward.Coding & Debugging.K=500": -87.70949720670392,
    "mixture_of_rewards.Coding & Debugging.K=500": -66.59947943118334,
    "haiku_reward.task_macro.K=500": -54.58343588166844,
    "llama_reward.task_macro.K=500": -27.20379505415682,
    "gpt4t_reward.task_macro.K=500": -73.71854521501764,
    "mixture_of_rewards.K=500": -42.20116678376507,
    "task_macro_reward.K=500": -51.835258716947635,
    "WB_score.Creative Tasks": 29.76623376623376,
    "WB_score.Planning & Reasoning": 15.428571428571427,
    "WB_score.Math & Data Analysis": -7.177419354838701,
    "WB_score.Information/Advice seeking": 27.66169154228855,
    "WB_score.Coding & Debugging": -6.794258373205739,
    "WB_score": 15.225048923679054,
    "WB_score.task_macro": 8.262075264042464,
    "Length": 2985.1052114060963,
    "Rank_ScoreMacro": 59,
    "Rank_TaskMacroReward.K": 60,
    "Rank_Avg": 59.5,
    "RewardScore_Avg": -21.786591726452585,
    "WB_Elo": 1033.3690594246566
  },
  "gemma-7b-it": {
    "Arena-Hard v0.1": "7.5",
    "AE2.0 LC": "10.4",
    "AE2.0": "6.9",
    "Arena Elo (hard-en) - 2024-07-16": 1046,
    "Arena Elo (hard-en) - latest": 1046,
    "haiku_reward.K=500": -47.36328125,
    "llama_reward.K=500": -25.41544477028348,
    "gpt4t_reward.K=500": -67.87109375,
    "haiku_reward.Creative Tasks.K=500": -36.03351955307262,
    "llama_reward.Creative Tasks.K=500": -28.690807799442897,
    "gpt4t_reward.Creative Tasks.K=500": -61.679790026246714,
    "mixture_of_rewards.Creative Tasks.K=500": -42.13470579292075,
    "haiku_reward.Planning & Reasoning.K=500": -50.54945054945055,
    "llama_reward.Planning & Reasoning.K=500": -24.80252764612954,
    "gpt4t_reward.Planning & Reasoning.K=500": -70.46153846153847,
    "mixture_of_rewards.Planning & Reasoning.K=500": -48.60450555237285,
    "haiku_reward.Math & Data Analysis.K=500": -59.716599190283404,
    "llama_reward.Math & Data Analysis.K=500": -11.428571428571429,
    "gpt4t_reward.Math & Data Analysis.K=500": -78.2520325203252,
    "mixture_of_rewards.Math & Data Analysis.K=500": -49.799067713060005,
    "haiku_reward.Information/Advice seeking.K=500": -49.744897959183675,
    "llama_reward.Information/Advice seeking.K=500": -38.64795918367347,
    "gpt4t_reward.Information/Advice seeking.K=500": -65.20100502512562,
    "mixture_of_rewards.Information/Advice seeking.K=500": -51.19795405599425,
    "haiku_reward.Coding & Debugging.K=500": -58.42105263157895,
    "llama_reward.Coding & Debugging.K=500": -14.659685863874344,
    "gpt4t_reward.Coding & Debugging.K=500": -77.02020202020202,
    "mixture_of_rewards.Coding & Debugging.K=500": -50.03364683855177,
    "haiku_reward.task_macro.K=500": -52.89582345526197,
    "llama_reward.task_macro.K=500": -21.913202442853226,
    "gpt4t_reward.task_macro.K=500": -72.07260145357229,
    "mixture_of_rewards.K=500": -46.88327325676116,
    "task_macro_reward.K=500": -48.96054245056249,
    "WB_score.Creative Tasks": 21.19170984455959,
    "WB_score.Planning & Reasoning": 10.164424514200299,
    "WB_score.Math & Data Analysis": -3.6507936507936556,
    "WB_score.Information/Advice seeking": 12.72277227722773,
    "WB_score.Coding & Debugging": 1.8009478672985857,
    "WB_score": 10.17578125,
    "WB_score.task_macro": 6.61975914869064,
    "Length": 1726.3440860215053,
    "Rank_ScoreMacro": 60,
    "Rank_TaskMacroReward.K": 59,
    "Rank_Avg": 59.5,
    "RewardScore_Avg": -21.170391650935926,
    "WB_Elo": 1058.181990260453
  },
  "gemma-2b-it": {
    "Arena-Hard v0.1": "3",
    "AE2.0 LC": "5.4",
    "AE2.0": "3.4",
    "Arena Elo (hard-en) - 2024-07-16": 977,
    "Arena Elo (hard-en) - latest": 977,
    "haiku_reward.K=500": -65.087890625,
    "llama_reward.K=500": -49.12109375,
    "gpt4t_reward.K=500": -80.810546875,
    "haiku_reward.Creative Tasks.K=500": -57.54189944134078,
    "llama_reward.Creative Tasks.K=500": -49.58217270194986,
    "gpt4t_reward.Creative Tasks.K=500": -75.06561679790026,
    "mixture_of_rewards.Creative Tasks.K=500": -60.72989631373031,
    "haiku_reward.Planning & Reasoning.K=500": -70.32967032967034,
    "llama_reward.Planning & Reasoning.K=500": -50.86887835703001,
    "gpt4t_reward.Planning & Reasoning.K=500": -83.05084745762711,
    "mixture_of_rewards.Planning & Reasoning.K=500": -68.08313204810916,
    "haiku_reward.Math & Data Analysis.K=500": -71.45748987854252,
    "llama_reward.Math & Data Analysis.K=500": -39.02439024390244,
    "gpt4t_reward.Math & Data Analysis.K=500": -88.41463414634147,
    "mixture_of_rewards.Math & Data Analysis.K=500": -66.29883808959546,
    "haiku_reward.Information/Advice seeking.K=500": -71.68367346938776,
    "llama_reward.Information/Advice seeking.K=500": -59.4147582697201,
    "gpt4t_reward.Information/Advice seeking.K=500": -81.4070351758794,
    "mixture_of_rewards.Information/Advice seeking.K=500": -70.83515563832908,
    "haiku_reward.Coding & Debugging.K=500": -76.31578947368422,
    "llama_reward.Coding & Debugging.K=500": -50.0,
    "gpt4t_reward.Coding & Debugging.K=500": -90.60913705583756,
    "mixture_of_rewards.Coding & Debugging.K=500": -72.30830884317392,
    "haiku_reward.task_macro.K=500": -71.01010935904145,
    "llama_reward.task_macro.K=500": -49.360556472306314,
    "gpt4t_reward.task_macro.K=500": -85.06898938295411,
    "mixture_of_rewards.K=500": -65.00651041666667,
    "task_macro_reward.K=500": -68.47988507143396,
    "WB_score.Creative Tasks": 7.220779220779221,
    "WB_score.Planning & Reasoning": -5.795795795795797,
    "WB_score.Math & Data Analysis": -18.64541832669323,
    "WB_score.Information/Advice seeking": -2.133995037220835,
    "WB_score.Coding & Debugging": -17.725118483412317,
    "WB_score": -5.249755142017634,
    "WB_score.task_macro": -9.691930072258819,
    "Length": 1590.0833333333333,
    "Rank_ScoreMacro": 61,
    "Rank_TaskMacroReward.K": 61,
    "Rank_Avg": 61.0,
    "RewardScore_Avg": -39.085907571846384,
    "WB_Elo": 996.5652530810216
  },
  "Llama-3-Instruct-8B-SimPO": {
    "Arena-Hard v0.1": "33.8",
    "AE2.0 LC": "44.7",
    "AE2.0": "40.5",
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": 14.84375,
    "llama_reward.K=500": 43.6950146627566,
    "gpt4t_reward.K=500": -13.8671875,
    "haiku_reward.Creative Tasks.K=500": 27.57660167130919,
    "llama_reward.Creative Tasks.K=500": 45.79831932773109,
    "gpt4t_reward.Creative Tasks.K=500": -5.936675461741425,
    "mixture_of_rewards.Creative Tasks.K=500": 22.479415179099618,
    "haiku_reward.Planning & Reasoning.K=500": 14.296998420221168,
    "llama_reward.Planning & Reasoning.K=500": 44.92868462757528,
    "gpt4t_reward.Planning & Reasoning.K=500": -15.50925925925926,
    "mixture_of_rewards.Planning & Reasoning.K=500": 14.572141262845731,
    "haiku_reward.Math & Data Analysis.K=500": 0.20242914979757085,
    "llama_reward.Math & Data Analysis.K=500": 48.78048780487805,
    "gpt4t_reward.Math & Data Analysis.K=500": -32.926829268292686,
    "mixture_of_rewards.Math & Data Analysis.K=500": 5.352029228794312,
    "haiku_reward.Information/Advice seeking.K=500": 22.94871794871795,
    "llama_reward.Information/Advice seeking.K=500": 43.8618925831202,
    "gpt4t_reward.Information/Advice seeking.K=500": 1.0075566750629723,
    "mixture_of_rewards.Information/Advice seeking.K=500": 22.606055735633706,
    "haiku_reward.Coding & Debugging.K=500": -0.26595744680851063,
    "llama_reward.Coding & Debugging.K=500": 54.473684210526315,
    "gpt4t_reward.Coding & Debugging.K=500": -32.6530612244898,
    "mixture_of_rewards.Coding & Debugging.K=500": 7.184888513076001,
    "haiku_reward.task_macro.K=500": 10.261277823948726,
    "llama_reward.task_macro.K=500": 48.17453220078121,
    "gpt4t_reward.task_macro.K=500": -20.07208423106368,
    "mixture_of_rewards.K=500": 14.890525720918866,
    "task_macro_reward.K=500": 12.78790859788875,
    "WB_score.Creative Tasks": 50.64599483204134,
    "WB_score.Planning & Reasoning": 40.86696562032884,
    "WB_score.Math & Data Analysis": 23.984063745019917,
    "WB_score.Information/Advice seeking": 47.871287128712865,
    "WB_score.Coding & Debugging": 31.753554502369674,
    "WB_score": 41.17302052785924,
    "WB_score.task_macro": 37.049721402304925,
    "Length": 2541.9257086999023,
    "Rank_ScoreMacro": 35,
    "Rank_TaskMacroReward.K": 17,
    "Rank_Avg": 26.0,
    "RewardScore_Avg": 24.91881500009684,
    "WB_Elo": 1147.2753876490617
  },
  "SELM-Zephyr-7B-iter-3": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "24.00",
    "AE2.0": "-",
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": -6.640625,
    "llama_reward.K=500": 20.41015625,
    "gpt4t_reward.K=500": -32.12890625,
    "haiku_reward.Creative Tasks.K=500": 11.614730878186968,
    "llama_reward.Creative Tasks.K=500": 26.504297994269344,
    "gpt4t_reward.Creative Tasks.K=500": -22.849462365591396,
    "mixture_of_rewards.Creative Tasks.K=500": 5.089855502288305,
    "haiku_reward.Planning & Reasoning.K=500": -8.72,
    "llama_reward.Planning & Reasoning.K=500": 23.909531502423263,
    "gpt4t_reward.Planning & Reasoning.K=500": -34.305993690851736,
    "mixture_of_rewards.Planning & Reasoning.K=500": -6.37215406280949,
    "haiku_reward.Math & Data Analysis.K=500": -27.066115702479337,
    "llama_reward.Math & Data Analysis.K=500": 25.518672199170123,
    "gpt4t_reward.Math & Data Analysis.K=500": -51.041666666666664,
    "mixture_of_rewards.Math & Data Analysis.K=500": -17.529703389991962,
    "haiku_reward.Information/Advice seeking.K=500": -0.13089005235602094,
    "llama_reward.Information/Advice seeking.K=500": 24.214659685863875,
    "gpt4t_reward.Information/Advice seeking.K=500": -20.854922279792746,
    "mixture_of_rewards.Information/Advice seeking.K=500": 1.076282451238369,
    "haiku_reward.Coding & Debugging.K=500": -38.12154696132597,
    "llama_reward.Coding & Debugging.K=500": 9.217877094972067,
    "gpt4t_reward.Coding & Debugging.K=500": -55.4054054054054,
    "mixture_of_rewards.Coding & Debugging.K=500": -28.10302509058643,
    "haiku_reward.task_macro.K=500": -16.822916106170595,
    "llama_reward.task_macro.K=500": 20.703384569988813,
    "gpt4t_reward.task_macro.K=500": -40.051965985184914,
    "mixture_of_rewards.K=500": -6.119791666666667,
    "task_macro_reward.K=500": -12.057165840455566,
    "WB_score.Creative Tasks": 44.70284237726098,
    "WB_score.Planning & Reasoning": 31.58682634730539,
    "WB_score.Math & Data Analysis": 12.669322709163353,
    "WB_score.Information/Advice seeking": 40.99009900990099,
    "WB_score.Coding & Debugging": 11.037735849056602,
    "WB_score": 31.5234375,
    "WB_score.task_macro": 25.061899136983598,
    "Length": 2823.7800586510266,
    "Rank_ScoreMacro": 52,
    "Rank_TaskMacroReward.K": 42,
    "Rank_Avg": 47.0,
    "RewardScore_Avg": 6.502366648264016,
    "WB_Elo": 1122.6875139363128
  },
  "Qwen2-72B-Instruct": {
    "Arena-Hard v0.1": "48.1",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1182,
    "Arena Elo (hard-en) - latest": 1182,
    "haiku_reward.K=500": 8.0078125,
    "llama_reward.K=500": 33.203125,
    "gpt4t_reward.K=500": -26.26953125,
    "haiku_reward.Creative Tasks.K=500": 10.140845070422536,
    "llama_reward.Creative Tasks.K=500": 24.289772727272727,
    "gpt4t_reward.Creative Tasks.K=500": -26.747311827956988,
    "mixture_of_rewards.Creative Tasks.K=500": 2.5611019899127583,
    "haiku_reward.Planning & Reasoning.K=500": 8.439490445859873,
    "llama_reward.Planning & Reasoning.K=500": 38.24476650563607,
    "gpt4t_reward.Planning & Reasoning.K=500": -26.295133437990582,
    "mixture_of_rewards.Planning & Reasoning.K=500": 6.796374504501788,
    "haiku_reward.Math & Data Analysis.K=500": 13.991769547325102,
    "llama_reward.Math & Data Analysis.K=500": 56.22406639004149,
    "gpt4t_reward.Math & Data Analysis.K=500": -28.09917355371901,
    "mixture_of_rewards.Math & Data Analysis.K=500": 14.03888746121586,
    "haiku_reward.Information/Advice seeking.K=500": 6.314432989690721,
    "llama_reward.Information/Advice seeking.K=500": 30.05181347150259,
    "gpt4t_reward.Information/Advice seeking.K=500": -17.647058823529413,
    "mixture_of_rewards.Information/Advice seeking.K=500": 6.239729212554633,
    "haiku_reward.Coding & Debugging.K=500": 2.393617021276596,
    "llama_reward.Coding & Debugging.K=500": 47.340425531914896,
    "gpt4t_reward.Coding & Debugging.K=500": -39.84375,
    "mixture_of_rewards.Coding & Debugging.K=500": 3.2967641843971642,
    "haiku_reward.task_macro.K=500": 7.860926559731578,
    "llama_reward.task_macro.K=500": 41.66090587457757,
    "gpt4t_reward.task_macro.K=500": -28.922469027964798,
    "mixture_of_rewards.K=500": 4.98046875,
    "task_macro_reward.K=500": 6.866454468781449,
    "WB_score.Creative Tasks": 49.92248062015504,
    "WB_score.Planning & Reasoning": 46.84603886397609,
    "WB_score.Math & Data Analysis": 40.95238095238095,
    "WB_score.Information/Advice seeking": 49.50495049504951,
    "WB_score.Coding & Debugging": 39.81132075471699,
    "WB_score": 46.40625,
    "WB_score.task_macro": 44.497691296234095,
    "Length": 2856.4482421875,
    "Rank_ScoreMacro": 25,
    "Rank_TaskMacroReward.K": 21,
    "Rank_Avg": 23.0,
    "RewardScore_Avg": 25.68207288250777,
    "WB_Elo": 1176.3672811642498
  },
  "Hermes-2-Theta-Llama-3-8B": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": -16.129032258064516,
    "llama_reward.K=500": 12.365591397849462,
    "gpt4t_reward.K=500": -46.57869012707722,
    "haiku_reward.Creative Tasks.K=500": -11.396011396011396,
    "llama_reward.Creative Tasks.K=500": 2.857142857142857,
    "gpt4t_reward.Creative Tasks.K=500": -47.96747967479675,
    "mixture_of_rewards.Creative Tasks.K=500": -18.835449404555096,
    "haiku_reward.Planning & Reasoning.K=500": -21.279999999999998,
    "llama_reward.Planning & Reasoning.K=500": 15.569823434991974,
    "gpt4t_reward.Planning & Reasoning.K=500": -48.26498422712934,
    "mixture_of_rewards.Planning & Reasoning.K=500": -17.991720264045785,
    "haiku_reward.Math & Data Analysis.K=500": -24.691358024691358,
    "llama_reward.Math & Data Analysis.K=500": 32.17213114754098,
    "gpt4t_reward.Math & Data Analysis.K=500": -54.54545454545454,
    "mixture_of_rewards.Math & Data Analysis.K=500": -15.688227140868307,
    "haiku_reward.Information/Advice seeking.K=500": -14.857881136950905,
    "llama_reward.Information/Advice seeking.K=500": 9.043927648578812,
    "gpt4t_reward.Information/Advice seeking.K=500": -36.607142857142854,
    "mixture_of_rewards.Information/Advice seeking.K=500": -14.140365448504982,
    "haiku_reward.Coding & Debugging.K=500": -26.38888888888889,
    "llama_reward.Coding & Debugging.K=500": 22.5,
    "gpt4t_reward.Coding & Debugging.K=500": -63.387978142076506,
    "mixture_of_rewards.Coding & Debugging.K=500": -22.42562234365513,
    "haiku_reward.task_macro.K=500": -21.288186460320283,
    "llama_reward.task_macro.K=500": 18.520195285533998,
    "gpt4t_reward.task_macro.K=500": -51.69489568151944,
    "mixture_of_rewards.K=500": -16.780710329097428,
    "task_macro_reward.K=500": -18.154295618768575,
    "WB_score.Creative Tasks": 39.79328165374676,
    "WB_score.Planning & Reasoning": 33.65269461077844,
    "WB_score.Math & Data Analysis": 18.725099601593627,
    "WB_score.Information/Advice seeking": 41.584158415841586,
    "WB_score.Coding & Debugging": 23.113207547169807,
    "WB_score": 32.9423264907136,
    "WB_score.task_macro": 29.635207776375477,
    "Length": 2742.169110459433,
    "Rank_ScoreMacro": 46,
    "Rank_TaskMacroReward.K": 47,
    "Rank_Avg": 46.5,
    "RewardScore_Avg": 5.740456078803451,
    "WB_Elo": 1123.1201291077534
  },
  "yi-large": {
    "Arena-Hard v0.1": "63.7",
    "AE2.0 LC": "51.9",
    "AE2.0": "57.5",
    "Arena Elo (hard-en) - 2024-07-16": 1198,
    "Arena Elo (hard-en) - latest": 1198,
    "haiku_reward.K=500": 15.478515625,
    "llama_reward.K=500": 37.573385518590996,
    "gpt4t_reward.K=500": -20.009784735812133,
    "haiku_reward.Creative Tasks.K=500": 22.701149425287355,
    "llama_reward.Creative Tasks.K=500": 31.571428571428573,
    "gpt4t_reward.Creative Tasks.K=500": -16.216216216216218,
    "mixture_of_rewards.Creative Tasks.K=500": 12.685453926833235,
    "haiku_reward.Planning & Reasoning.K=500": 16.613162118780096,
    "llama_reward.Planning & Reasoning.K=500": 43.983739837398375,
    "gpt4t_reward.Planning & Reasoning.K=500": -21.484992101105846,
    "mixture_of_rewards.Planning & Reasoning.K=500": 13.037303285024208,
    "haiku_reward.Math & Data Analysis.K=500": 20.041322314049587,
    "llama_reward.Math & Data Analysis.K=500": 56.903765690376574,
    "gpt4t_reward.Math & Data Analysis.K=500": -22.916666666666664,
    "mixture_of_rewards.Math & Data Analysis.K=500": 18.009473779253167,
    "haiku_reward.Information/Advice seeking.K=500": 12.207792207792208,
    "llama_reward.Information/Advice seeking.K=500": 32.8125,
    "gpt4t_reward.Information/Advice seeking.K=500": -14.83375959079284,
    "mixture_of_rewards.Information/Advice seeking.K=500": 10.06217753899979,
    "haiku_reward.Coding & Debugging.K=500": 10.220994475138122,
    "llama_reward.Coding & Debugging.K=500": 55.80110497237569,
    "gpt4t_reward.Coding & Debugging.K=500": -34.22459893048128,
    "mixture_of_rewards.Coding & Debugging.K=500": 10.599166839010843,
    "haiku_reward.task_macro.K=500": 15.597986721038989,
    "llama_reward.task_macro.K=500": 46.74313915543336,
    "gpt4t_reward.task_macro.K=500": -23.534122791021755,
    "mixture_of_rewards.K=500": 11.014038802592955,
    "task_macro_reward.K=500": 12.935667695150196,
    "WB_score.Creative Tasks": 51.80156657963445,
    "WB_score.Planning & Reasoning": 51.33834586466165,
    "WB_score.Math & Data Analysis": 44.46215139442231,
    "WB_score.Information/Advice seeking": 50.96774193548388,
    "WB_score.Coding & Debugging": 47.71428571428572,
    "WB_score": 48.93450635386118,
    "WB_score.task_macro": 48.92726960200772,
    "Length": 3095.335952848723,
    "Rank_ScoreMacro": 14,
    "Rank_TaskMacroReward.K": 16,
    "Rank_Avg": 15.0,
    "RewardScore_Avg": 30.931468648578957,
    "WB_Elo": 1189.4528661631805
  },
  "Yi-1.5-34B-Chat": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1160,
    "Arena Elo (hard-en) - latest": 1160,
    "haiku_reward.K=500": 13.671875,
    "llama_reward.K=500": 34.50635386119257,
    "gpt4t_reward.K=500": -20.3125,
    "haiku_reward.Creative Tasks.K=500": 22.910662824207492,
    "llama_reward.Creative Tasks.K=500": 32.42074927953891,
    "gpt4t_reward.Creative Tasks.K=500": -16.391184573002754,
    "mixture_of_rewards.Creative Tasks.K=500": 12.980075843581217,
    "haiku_reward.Planning & Reasoning.K=500": 14.70113085621971,
    "llama_reward.Planning & Reasoning.K=500": 41.54471544715447,
    "gpt4t_reward.Planning & Reasoning.K=500": -19.187898089171977,
    "mixture_of_rewards.Planning & Reasoning.K=500": 12.352649404734066,
    "haiku_reward.Math & Data Analysis.K=500": 14.915966386554622,
    "llama_reward.Math & Data Analysis.K=500": 49.37238493723849,
    "gpt4t_reward.Math & Data Analysis.K=500": -31.35593220338983,
    "mixture_of_rewards.Math & Data Analysis.K=500": 10.977473040134427,
    "haiku_reward.Information/Advice seeking.K=500": 11.688311688311687,
    "llama_reward.Information/Advice seeking.K=500": 33.33333333333333,
    "gpt4t_reward.Information/Advice seeking.K=500": -11.953727506426736,
    "mixture_of_rewards.Information/Advice seeking.K=500": 11.022639171739426,
    "haiku_reward.Coding & Debugging.K=500": 3.0386740331491713,
    "llama_reward.Coding & Debugging.K=500": 43.0939226519337,
    "gpt4t_reward.Coding & Debugging.K=500": -40.32258064516129,
    "mixture_of_rewards.Coding & Debugging.K=500": 1.936672013307195,
    "haiku_reward.task_macro.K=500": 12.065744774021733,
    "llama_reward.task_macro.K=500": 41.343380463340665,
    "gpt4t_reward.task_macro.K=500": -25.874719692132174,
    "mixture_of_rewards.K=500": 9.28857628706419,
    "task_macro_reward.K=500": 9.178135181743407,
    "WB_score.Creative Tasks": 53.523316062176164,
    "WB_score.Planning & Reasoning": 48.108108108108105,
    "WB_score.Math & Data Analysis": 39.43775100401606,
    "WB_score.Information/Advice seeking": 50.29702970297029,
    "WB_score.Coding & Debugging": 42.08530805687204,
    "WB_score": 47.350928641251215,
    "WB_score.task_macro": 45.613463477590955,
    "Length": 3523.557843137255,
    "Rank_ScoreMacro": 23,
    "Rank_TaskMacroReward.K": 19,
    "Rank_Avg": 21.0,
    "RewardScore_Avg": 27.39579932966718,
    "WB_Elo": 1162.7919494137102
  },
  "reka-flash-20240226": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1127,
    "Arena Elo (hard-en) - latest": 1127,
    "haiku_reward.K=500": -2.490234375,
    "llama_reward.K=500": 25.29296875,
    "gpt4t_reward.K=500": -32.275390625,
    "haiku_reward.Creative Tasks.K=500": 4.621848739495799,
    "llama_reward.Creative Tasks.K=500": 17.548746518105848,
    "gpt4t_reward.Creative Tasks.K=500": -28.891820580474935,
    "mixture_of_rewards.Creative Tasks.K=500": -2.2404084409577627,
    "haiku_reward.Planning & Reasoning.K=500": -4.881889763779528,
    "llama_reward.Planning & Reasoning.K=500": 27.488151658767773,
    "gpt4t_reward.Planning & Reasoning.K=500": -34.20647149460709,
    "mixture_of_rewards.Planning & Reasoning.K=500": -3.866736533206281,
    "haiku_reward.Math & Data Analysis.K=500": -10.365853658536585,
    "llama_reward.Math & Data Analysis.K=500": 42.073170731707314,
    "gpt4t_reward.Math & Data Analysis.K=500": -45.51020408163266,
    "mixture_of_rewards.Math & Data Analysis.K=500": -4.600962336153977,
    "haiku_reward.Information/Advice seeking.K=500": -2.557544757033248,
    "llama_reward.Information/Advice seeking.K=500": 16.581632653061224,
    "gpt4t_reward.Information/Advice seeking.K=500": -23.67758186397985,
    "mixture_of_rewards.Information/Advice seeking.K=500": -3.2178313226506248,
    "haiku_reward.Coding & Debugging.K=500": -11.2565445026178,
    "llama_reward.Coding & Debugging.K=500": 44.27083333333333,
    "gpt4t_reward.Coding & Debugging.K=500": -44.923857868020306,
    "mixture_of_rewards.Coding & Debugging.K=500": -3.969856345768259,
    "haiku_reward.task_macro.K=500": -6.3465538293811115,
    "llama_reward.task_macro.K=500": 32.206842046459485,
    "gpt4t_reward.task_macro.K=500": -37.18467631013458,
    "mixture_of_rewards.K=500": -3.1575520833333335,
    "task_macro_reward.K=500": -3.7747960310187345,
    "WB_score.Creative Tasks": 42.44155844155845,
    "WB_score.Planning & Reasoning": 35.01501501501501,
    "WB_score.Math & Data Analysis": 20.48,
    "WB_score.Information/Advice seeking": 41.53465346534654,
    "WB_score.Coding & Debugging": 22.085308056872037,
    "WB_score": 34.60410557184751,
    "WB_score.task_macro": 30.363615402031144,
    "Length": 2103.0098039215686,
    "Rank_ScoreMacro": 43,
    "Rank_TaskMacroReward.K": 38,
    "Rank_Avg": 40.5,
    "RewardScore_Avg": 13.294409685506205,
    "WB_Elo": 1130.7430402344874
  },
  "gemini-1.5-pro": {
    "Arena-Hard v0.1": "72.0",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1245,
    "Arena Elo (hard-en) - latest": 1245,
    "haiku_reward.K=500": 29.58984375,
    "llama_reward.K=500": 45.99609375,
    "gpt4t_reward.K=500": -0.6842619745845552,
    "haiku_reward.Creative Tasks.K=500": 35.84615384615385,
    "llama_reward.Creative Tasks.K=500": 44.5141065830721,
    "gpt4t_reward.Creative Tasks.K=500": -4.776119402985075,
    "mixture_of_rewards.Creative Tasks.K=500": 25.194713675413624,
    "haiku_reward.Planning & Reasoning.K=500": 33.6472602739726,
    "llama_reward.Planning & Reasoning.K=500": 56.04490500863558,
    "gpt4t_reward.Planning & Reasoning.K=500": 0.4251700680272109,
    "mixture_of_rewards.Planning & Reasoning.K=500": 30.039111783545135,
    "haiku_reward.Math & Data Analysis.K=500": 35.1063829787234,
    "llama_reward.Math & Data Analysis.K=500": 65.02145922746782,
    "gpt4t_reward.Math & Data Analysis.K=500": -3.896103896103896,
    "mixture_of_rewards.Math & Data Analysis.K=500": 32.07724610336244,
    "haiku_reward.Information/Advice seeking.K=500": 29.18918918918919,
    "llama_reward.Information/Advice seeking.K=500": 47.002724795640326,
    "gpt4t_reward.Information/Advice seeking.K=500": 3.783783783783784,
    "mixture_of_rewards.Information/Advice seeking.K=500": 26.6585659228711,
    "haiku_reward.Coding & Debugging.K=500": 48.089171974522294,
    "llama_reward.Coding & Debugging.K=500": 72.5,
    "gpt4t_reward.Coding & Debugging.K=500": 5.3125,
    "mixture_of_rewards.Coding & Debugging.K=500": 41.96722399150743,
    "haiku_reward.task_macro.K=500": 37.282503600907546,
    "llama_reward.task_macro.K=500": 59.623513131900765,
    "gpt4t_reward.task_macro.K=500": 0.7843709105842986,
    "mixture_of_rewards.K=500": 24.96722517513848,
    "task_macro_reward.K=500": 32.563462547797535,
    "WB_score.Creative Tasks": 55.124653739612185,
    "WB_score.Planning & Reasoning": 53.73271889400922,
    "WB_score.Math & Data Analysis": 48.59437751004016,
    "WB_score.Information/Advice seeking": 52.22506393861893,
    "WB_score.Coding & Debugging": 55.223880597014926,
    "WB_score": 47.3828125,
    "WB_score.task_macro": 52.95184246265066,
    "Length": 3247.9673135852913,
    "Rank_ScoreMacro": 11,
    "Rank_TaskMacroReward.K": 2,
    "Rank_Avg": 6.5,
    "RewardScore_Avg": 42.7576525052241,
    "WB_Elo": 1221.1308875018053
  },
  "gemini-1.5-flash": {
    "Arena-Hard v0.1": "49.6",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1212,
    "Arena Elo (hard-en) - latest": 1212,
    "haiku_reward.K=500": 17.28515625,
    "llama_reward.K=500": 36.42578125,
    "gpt4t_reward.K=500": -11.767578125,
    "haiku_reward.Creative Tasks.K=500": 21.26984126984127,
    "llama_reward.Creative Tasks.K=500": 31.87702265372168,
    "gpt4t_reward.Creative Tasks.K=500": -14.018691588785046,
    "mixture_of_rewards.Creative Tasks.K=500": 13.042724111592634,
    "haiku_reward.Planning & Reasoning.K=500": 19.584055459272097,
    "llama_reward.Planning & Reasoning.K=500": 45.47038327526132,
    "gpt4t_reward.Planning & Reasoning.K=500": -12.629757785467127,
    "mixture_of_rewards.Planning & Reasoning.K=500": 17.474893649688763,
    "haiku_reward.Math & Data Analysis.K=500": 21.982758620689655,
    "llama_reward.Math & Data Analysis.K=500": 57.173913043478265,
    "gpt4t_reward.Math & Data Analysis.K=500": -11.18421052631579,
    "mixture_of_rewards.Math & Data Analysis.K=500": 22.657487045950706,
    "haiku_reward.Information/Advice seeking.K=500": 13.019390581717452,
    "llama_reward.Information/Advice seeking.K=500": 35.041551246537395,
    "gpt4t_reward.Information/Advice seeking.K=500": -13.598901098901099,
    "mixture_of_rewards.Information/Advice seeking.K=500": 11.487346909784582,
    "haiku_reward.Coding & Debugging.K=500": 33.97435897435898,
    "llama_reward.Coding & Debugging.K=500": 64.55696202531645,
    "gpt4t_reward.Coding & Debugging.K=500": -15.286624203821656,
    "mixture_of_rewards.Coding & Debugging.K=500": 27.74823226528459,
    "haiku_reward.task_macro.K=500": 23.01689268082889,
    "llama_reward.task_macro.K=500": 49.87953040651882,
    "gpt4t_reward.task_macro.K=500": -13.32383360663055,
    "mixture_of_rewards.K=500": 13.981119791666666,
    "task_macro_reward.K=500": 19.857529826905715,
    "WB_score.Creative Tasks": 51.65745856353592,
    "WB_score.Planning & Reasoning": 50.78582434514638,
    "WB_score.Math & Data Analysis": 45.322580645161295,
    "WB_score.Information/Advice seeking": 48.66666666666667,
    "WB_score.Coding & Debugging": 48.72549019607844,
    "WB_score": 44.14872798434443,
    "WB_score.task_macro": 48.85062170599164,
    "Length": 3654.3993871297243,
    "Rank_ScoreMacro": 15,
    "Rank_TaskMacroReward.K": 10,
    "Rank_Avg": 12.5,
    "RewardScore_Avg": 34.35407576644868,
    "WB_Elo": 1196.8042835473223
  },
  "reka-core-20240501": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1175,
    "Arena Elo (hard-en) - latest": 1175,
    "haiku_reward.K=500": 21.142578125,
    "llama_reward.K=500": 42.48046875,
    "gpt4t_reward.K=500": -14.501953125,
    "haiku_reward.Creative Tasks.K=500": 28.613569321533923,
    "llama_reward.Creative Tasks.K=500": 40.828402366863905,
    "gpt4t_reward.Creative Tasks.K=500": -12.957746478873238,
    "mixture_of_rewards.Creative Tasks.K=500": 18.82807506984153,
    "haiku_reward.Planning & Reasoning.K=500": 23.71900826446281,
    "llama_reward.Planning & Reasoning.K=500": 47.920133111480865,
    "gpt4t_reward.Planning & Reasoning.K=500": -16.34146341463415,
    "mixture_of_rewards.Planning & Reasoning.K=500": 18.43255932043651,
    "haiku_reward.Math & Data Analysis.K=500": 23.580786026200872,
    "llama_reward.Math & Data Analysis.K=500": 60.26200873362445,
    "gpt4t_reward.Math & Data Analysis.K=500": -18.06167400881057,
    "mixture_of_rewards.Math & Data Analysis.K=500": 21.92704025033825,
    "haiku_reward.Information/Advice seeking.K=500": 17.06989247311828,
    "llama_reward.Information/Advice seeking.K=500": 40.296495956873315,
    "gpt4t_reward.Information/Advice seeking.K=500": -11.497326203208557,
    "mixture_of_rewards.Information/Advice seeking.K=500": 15.289687408927678,
    "haiku_reward.Coding & Debugging.K=500": 23.224043715846996,
    "llama_reward.Coding & Debugging.K=500": 59.94475138121547,
    "gpt4t_reward.Coding & Debugging.K=500": -26.203208556149733,
    "mixture_of_rewards.Coding & Debugging.K=500": 18.988528846970908,
    "haiku_reward.task_macro.K=500": 23.025011582567114,
    "llama_reward.task_macro.K=500": 51.732565789596165,
    "gpt4t_reward.task_macro.K=500": -18.177764602975465,
    "mixture_of_rewards.K=500": 16.373697916666668,
    "task_macro_reward.K=500": 18.859937589729274,
    "WB_score.Creative Tasks": 55.4874651810585,
    "WB_score.Planning & Reasoning": 48.00632911392405,
    "WB_score.Math & Data Analysis": 40.34188034188034,
    "WB_score.Information/Advice seeking": 52.254641909814325,
    "WB_score.Coding & Debugging": 40.60301507537689,
    "WB_score": 41.03515625,
    "WB_score.task_macro": 45.90279465292558,
    "Length": 2592.589397089397,
    "Rank_ScoreMacro": 21,
    "Rank_TaskMacroReward.K": 11,
    "Rank_Avg": 16.0,
    "RewardScore_Avg": 32.381366121327424,
    "WB_Elo": 1174.6634120985846
  },
  "yi-large-preview": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1229,
    "Arena Elo (hard-en) - latest": 1229,
    "haiku_reward.K=500": 28.955078125,
    "llama_reward.K=500": 47.65395894428153,
    "gpt4t_reward.K=500": -2.590420332355816,
    "haiku_reward.Creative Tasks.K=500": 33.87096774193548,
    "llama_reward.Creative Tasks.K=500": 40.680473372781066,
    "gpt4t_reward.Creative Tasks.K=500": -2.661064425770308,
    "mixture_of_rewards.Creative Tasks.K=500": 23.963458896315412,
    "haiku_reward.Planning & Reasoning.K=500": 32.459016393442624,
    "llama_reward.Planning & Reasoning.K=500": 56.15640599001664,
    "gpt4t_reward.Planning & Reasoning.K=500": -3.715670436187399,
    "mixture_of_rewards.Planning & Reasoning.K=500": 28.299917315757288,
    "haiku_reward.Math & Data Analysis.K=500": 38.125,
    "llama_reward.Math & Data Analysis.K=500": 69.27966101694916,
    "gpt4t_reward.Math & Data Analysis.K=500": -6.512605042016808,
    "mixture_of_rewards.Math & Data Analysis.K=500": 33.630685324977456,
    "haiku_reward.Information/Advice seeking.K=500": 23.69109947643979,
    "llama_reward.Information/Advice seeking.K=500": 48.94459102902375,
    "gpt4t_reward.Information/Advice seeking.K=500": 4.805194805194805,
    "mixture_of_rewards.Information/Advice seeking.K=500": 25.813628436886116,
    "haiku_reward.Coding & Debugging.K=500": 37.5,
    "llama_reward.Coding & Debugging.K=500": 70.6896551724138,
    "gpt4t_reward.Coding & Debugging.K=500": -9.831460674157304,
    "mixture_of_rewards.Coding & Debugging.K=500": 32.78606483275217,
    "haiku_reward.task_macro.K=500": 33.74264820423177,
    "llama_reward.task_macro.K=500": 59.97598261645168,
    "gpt4t_reward.task_macro.K=500": -4.4575063239866815,
    "mixture_of_rewards.K=500": 24.6728722456419,
    "task_macro_reward.K=500": 29.753708165565588,
    "WB_score.Creative Tasks": 57.64397905759162,
    "WB_score.Planning & Reasoning": 56.606606606606604,
    "WB_score.Math & Data Analysis": 51.92,
    "WB_score.Information/Advice seeking": 57.72277227722773,
    "WB_score.Coding & Debugging": 54.28571428571429,
    "WB_score": 54.83870967741936,
    "WB_score.task_macro": 55.294625232024785,
    "Length": 3512.678149606299,
    "Rank_ScoreMacro": 5,
    "Rank_TaskMacroReward.K": 5,
    "Rank_Avg": 5.0,
    "RewardScore_Avg": 42.524166698795185,
    "WB_Elo": 1216.4791603920064
  },
  "nemotron-4-340b-instruct": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1185,
    "Arena Elo (hard-en) - latest": 1185,
    "haiku_reward.K=500": 23.92578125,
    "llama_reward.K=500": 43.212890625,
    "gpt4t_reward.K=500": -10.595703125,
    "haiku_reward.Creative Tasks.K=500": 26.420454545454547,
    "llama_reward.Creative Tasks.K=500": 37.464387464387464,
    "gpt4t_reward.Creative Tasks.K=500": -10.21505376344086,
    "mixture_of_rewards.Creative Tasks.K=500": 17.88992941546705,
    "haiku_reward.Planning & Reasoning.K=500": 22.31139646869984,
    "llama_reward.Planning & Reasoning.K=500": 47.58842443729904,
    "gpt4t_reward.Planning & Reasoning.K=500": -13.679245283018867,
    "mixture_of_rewards.Planning & Reasoning.K=500": 18.740191874326673,
    "haiku_reward.Math & Data Analysis.K=500": 26.89075630252101,
    "llama_reward.Math & Data Analysis.K=500": 59.75103734439834,
    "gpt4t_reward.Math & Data Analysis.K=500": -17.016806722689076,
    "mixture_of_rewards.Math & Data Analysis.K=500": 23.208328974743427,
    "haiku_reward.Information/Advice seeking.K=500": 21.52061855670103,
    "llama_reward.Information/Advice seeking.K=500": 39.203084832904885,
    "gpt4t_reward.Information/Advice seeking.K=500": -3.4263959390862944,
    "mixture_of_rewards.Information/Advice seeking.K=500": 19.09910248350654,
    "haiku_reward.Coding & Debugging.K=500": 36.43617021276596,
    "llama_reward.Coding & Debugging.K=500": 65.59139784946237,
    "gpt4t_reward.Coding & Debugging.K=500": -12.30366492146597,
    "mixture_of_rewards.Coding & Debugging.K=500": 29.907967713587453,
    "haiku_reward.task_macro.K=500": 27.30019070412764,
    "llama_reward.task_macro.K=500": 52.49691001257315,
    "gpt4t_reward.task_macro.K=500": -12.036372276701108,
    "mixture_of_rewards.K=500": 18.84765625,
    "task_macro_reward.K=500": 22.5869094799999,
    "WB_score.Creative Tasks": 53.3160621761658,
    "WB_score.Planning & Reasoning": 49.12912912912914,
    "WB_score.Math & Data Analysis": 40.80321285140562,
    "WB_score.Information/Advice seeking": 53.00248138957816,
    "WB_score.Coding & Debugging": 46.25592417061611,
    "WB_score": 48.84765625,
    "WB_score.task_macro": 47.67250981186394,
    "Length": 2754.0098039215686,
    "Rank_ScoreMacro": 19,
    "Rank_TaskMacroReward.K": 8,
    "Rank_Avg": 13.5,
    "RewardScore_Avg": 35.12970964593192,
    "WB_Elo": 1184.3773976027633
  },
  "claude-3-5-sonnet-20240620": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1271,
    "Arena Elo (hard-en) - latest": 1271,
    "haiku_reward.K=500": 35.546875,
    "llama_reward.K=500": 50.341796875,
    "gpt4t_reward.K=500": 2.783203125,
    "haiku_reward.Creative Tasks.K=500": 34.58083832335329,
    "llama_reward.Creative Tasks.K=500": 39.54545454545455,
    "gpt4t_reward.Creative Tasks.K=500": -5.994152046783626,
    "mixture_of_rewards.Creative Tasks.K=500": 22.710713607341404,
    "haiku_reward.Planning & Reasoning.K=500": 39.04448105436573,
    "llama_reward.Planning & Reasoning.K=500": 59.60264900662252,
    "gpt4t_reward.Planning & Reasoning.K=500": 5.172413793103448,
    "mixture_of_rewards.Planning & Reasoning.K=500": 34.606514618030566,
    "haiku_reward.Math & Data Analysis.K=500": 46.041666666666664,
    "llama_reward.Math & Data Analysis.K=500": 76.35983263598327,
    "gpt4t_reward.Math & Data Analysis.K=500": 7.773109243697479,
    "mixture_of_rewards.Math & Data Analysis.K=500": 43.39153618211581,
    "haiku_reward.Information/Advice seeking.K=500": 34.20365535248042,
    "llama_reward.Information/Advice seeking.K=500": 52.34986945169713,
    "gpt4t_reward.Information/Advice seeking.K=500": 9.765625,
    "mixture_of_rewards.Information/Advice seeking.K=500": 32.10638326805918,
    "haiku_reward.Coding & Debugging.K=500": 50.595238095238095,
    "llama_reward.Coding & Debugging.K=500": 77.32558139534885,
    "gpt4t_reward.Coding & Debugging.K=500": 11.470588235294118,
    "mixture_of_rewards.Coding & Debugging.K=500": 46.46380257529369,
    "haiku_reward.task_macro.K=500": 42.32304763783335,
    "llama_reward.task_macro.K=500": 64.53794736841002,
    "gpt4t_reward.task_macro.K=500": 6.927158843326868,
    "mixture_of_rewards.K=500": 29.557291666666668,
    "task_macro_reward.K=500": 37.929384616523414,
    "WB_score.Creative Tasks": 55.60723514211887,
    "WB_score.Planning & Reasoning": 55.635276532137524,
    "WB_score.Math & Data Analysis": 50.15873015873016,
    "WB_score.Information/Advice seeking": 55.54455445544555,
    "WB_score.Coding & Debugging": 56.509433962264154,
    "WB_score": 54.53125,
    "WB_score.task_macro": 54.69508456618439,
    "Length": 2911.845703125,
    "Rank_ScoreMacro": 7,
    "Rank_TaskMacroReward.K": 1,
    "Rank_Avg": 4.0,
    "RewardScore_Avg": 46.3122345913539,
    "WB_Elo": 1226.3132607594066
  },
  "deepseek-coder-v2": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - latest": "-",
    "Arena Elo (hard-en) - 2024-07-16": "-",
    "haiku_reward.K=500": 15.380859375,
    "llama_reward.K=500": 37.451171875,
    "gpt4t_reward.K=500": -18.817204301075268,
    "haiku_reward.Creative Tasks.K=500": 22.869318181818183,
    "llama_reward.Creative Tasks.K=500": 34.285714285714285,
    "gpt4t_reward.Creative Tasks.K=500": -13.03763440860215,
    "mixture_of_rewards.Creative Tasks.K=500": 14.70579935297677,
    "haiku_reward.Planning & Reasoning.K=500": 15.569823434991974,
    "llama_reward.Planning & Reasoning.K=500": 42.407108239095315,
    "gpt4t_reward.Planning & Reasoning.K=500": -20.300157977883096,
    "mixture_of_rewards.Planning & Reasoning.K=500": 12.558924565401398,
    "haiku_reward.Math & Data Analysis.K=500": 17.28395061728395,
    "llama_reward.Math & Data Analysis.K=500": 54.356846473029044,
    "gpt4t_reward.Math & Data Analysis.K=500": -29.166666666666668,
    "mixture_of_rewards.Math & Data Analysis.K=500": 14.158043474548771,
    "haiku_reward.Information/Advice seeking.K=500": 9.455958549222798,
    "llama_reward.Information/Advice seeking.K=500": 29.792746113989637,
    "gpt4t_reward.Information/Advice seeking.K=500": -13.299232736572892,
    "mixture_of_rewards.Information/Advice seeking.K=500": 8.649823975546516,
    "haiku_reward.Coding & Debugging.K=500": 15.945945945945947,
    "llama_reward.Coding & Debugging.K=500": 58.602150537634415,
    "gpt4t_reward.Coding & Debugging.K=500": -30.104712041884817,
    "mixture_of_rewards.Coding & Debugging.K=500": 14.814461480565184,
    "haiku_reward.task_macro.K=500": 15.832692704480536,
    "llama_reward.task_macro.K=500": 46.33807087837697,
    "gpt4t_reward.task_macro.K=500": -22.877051778548907,
    "mixture_of_rewards.K=500": 11.338275649641579,
    "task_macro_reward.K=500": 13.097903934769533,
    "WB_score.Creative Tasks": 54.49350649350649,
    "WB_score.Planning & Reasoning": 49.24698795180723,
    "WB_score.Math & Data Analysis": 41.59362549800797,
    "WB_score.Information/Advice seeking": 51.54228855721392,
    "WB_score.Coding & Debugging": 44.85714285714286,
    "WB_score": 48.895405669599214,
    "WB_score.task_macro": 47.39521235239142,
    "Length": 2795.3091265947005,
    "Rank_ScoreMacro": 20,
    "Rank_TaskMacroReward.K": 15,
    "Rank_Avg": 17.5,
    "RewardScore_Avg": 30.246558143580476,
    "WB_Elo": 1183.530275223054
  },
  "gemma-2-9b-it": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1155,
    "Arena Elo (hard-en) - latest": 1155,
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 51.007751937984494,
    "WB_score.Planning & Reasoning": 46.65667166416792,
    "WB_score.Math & Data Analysis": 36.42857142857142,
    "WB_score.Information/Advice seeking": 48.960396039603964,
    "WB_score.Coding & Debugging": 36.66666666666666,
    "WB_score": 45.36203522504893,
    "WB_score.task_macro": 42.696193124381026,
    "Length": 2802.8923679060667,
    "Rank_ScoreMacro": 27,
    "Rank_TaskMacroReward.K": 23,
    "Rank_Avg": 25.0,
    "RewardScore_Avg": 21.348096562190513,
    "WB_Elo": 1159.347071190945
  },
  "deepseek-v2-chat-0628": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1233,
    "Arena Elo (hard-en) - latest": 1233,
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 56.43410852713178,
    "WB_score.Planning & Reasoning": 54.82810164424514,
    "WB_score.Math & Data Analysis": 51.42857142857142,
    "WB_score.Information/Advice seeking": 52.72277227722773,
    "WB_score.Coding & Debugging": 55.0,
    "WB_score": 53.80859375,
    "WB_score.task_macro": 53.994280411655694,
    "Length": 3252.376953125,
    "Rank_ScoreMacro": 8,
    "Rank_TaskMacroReward.K": 24,
    "Rank_Avg": 16.0,
    "RewardScore_Avg": 26.997140205827847,
    "WB_Elo": 1209.9997081626336
  },
  "deepseek-v2-coder-0628": {
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "Arena Elo (hard-en) - 2024-07-16": 1204,
    "Arena Elo (hard-en) - latest": 1204,
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 40.775193798449614,
    "WB_score.Planning & Reasoning": 47.17488789237669,
    "WB_score.Math & Data Analysis": 46.42857142857142,
    "WB_score.Information/Advice seeking": 40.04950495049505,
    "WB_score.Coding & Debugging": 48.86792452830189,
    "WB_score": 43.4375,
    "WB_score.task_macro": 45.66459211926647,
    "Length": 2580.181640625,
    "Rank_ScoreMacro": 22,
    "Rank_TaskMacroReward.K": 25,
    "Rank_Avg": 23.5,
    "RewardScore_Avg": 22.832296059633236,
    "WB_Elo": 1194.3052888237632
  },
  "Athene-70B": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 60.36175710594314,
    "WB_score.Planning & Reasoning": 60.95952023988005,
    "WB_score.Math & Data Analysis": 57.13147410358566,
    "WB_score.Information/Advice seeking": 60.79207920792079,
    "WB_score.Coding & Debugging": 58.95734597156398,
    "WB_score": 59.41291585127202,
    "WB_score.task_macro": 59.53736733195851,
    "Length": 3175.1438356164385,
    "Rank_ScoreMacro": 1,
    "Rank_TaskMacroReward.K": 26,
    "Rank_Avg": 13.5,
    "RewardScore_Avg": 29.768683665979253,
    "WB_Elo": 1204.5925588524296
  },
  "gpt-4o-mini-2024-07-18": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 60.051679586563296,
    "WB_score.Planning & Reasoning": 58.23617339312406,
    "WB_score.Math & Data Analysis": 54.04761904761905,
    "WB_score.Information/Advice seeking": 57.42574257425743,
    "WB_score.Coding & Debugging": 57.16981132075471,
    "WB_score": 57.265625,
    "WB_score.task_macro": 57.13689403451416,
    "Length": 3648.126953125,
    "Rank_ScoreMacro": 3,
    "Rank_TaskMacroReward.K": 27,
    "Rank_Avg": 15.0,
    "RewardScore_Avg": 28.56844701725708,
    "WB_Elo": 1191.6787570765769
  },
  "Mistral-Large-2": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 58.860103626943,
    "WB_score.Planning & Reasoning": 57.21556886227545,
    "WB_score.Math & Data Analysis": 52.66932270916335,
    "WB_score.Information/Advice seeking": 57.37623762376238,
    "WB_score.Coding & Debugging": 53.83886255924171,
    "WB_score": 55.80078125,
    "WB_score.task_macro": 55.56833516154802,
    "Length": 3503.6262230919765,
    "Rank_ScoreMacro": 4,
    "Rank_TaskMacroReward.K": 28,
    "Rank_Avg": 16.0,
    "RewardScore_Avg": 27.78416758077401,
    "WB_Elo": 1197.7105795590762
  },
  "gemma-2-9b-it-DPO": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 59.067357512953365,
    "WB_score.Planning & Reasoning": 55.47226386806596,
    "WB_score.Math & Data Analysis": 47.12,
    "WB_score.Information/Advice seeking": 58.21782178217822,
    "WB_score.Coding & Debugging": 50.52132701421801,
    "WB_score": 54.2578125,
    "WB_score.task_macro": 53.22295446230848,
    "Length": 3982.628795298727,
    "Rank_ScoreMacro": 10,
    "Rank_TaskMacroReward.K": 29,
    "Rank_Avg": 19.5,
    "RewardScore_Avg": 26.61147723115424,
    "WB_Elo": 1181.0736048785952
  },
  "gemma-2-9b-it-SimPO": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 57.97927461139896,
    "WB_score.Planning & Reasoning": 55.645645645645644,
    "WB_score.Math & Data Analysis": 48.59437751004016,
    "WB_score.Information/Advice seeking": 56.485148514851474,
    "WB_score.Coding & Debugging": 50.857142857142854,
    "WB_score": 54.07624633431085,
    "WB_score.task_macro": 53.27923406955029,
    "Length": 4277.667647058824,
    "Rank_ScoreMacro": 9,
    "Rank_TaskMacroReward.K": 30,
    "Rank_Avg": 19.5,
    "RewardScore_Avg": 26.639617034775146,
    "WB_Elo": 1180.4986055478087
  },
  "deepseekv2-chat": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 16.40625,
    "llama_reward.K=500": 39.208984375,
    "gpt4t_reward.K=500": -15.234375,
    "haiku_reward.Creative Tasks.K=500": 24.074074074074073,
    "llama_reward.Creative Tasks.K=500": 34.48275862068966,
    "gpt4t_reward.Creative Tasks.K=500": -11.756756756756758,
    "mixture_of_rewards.Creative Tasks.K=500": 15.60002531266899,
    "haiku_reward.Planning & Reasoning.K=500": 17.736757624398074,
    "llama_reward.Planning & Reasoning.K=500": 44.847020933977454,
    "gpt4t_reward.Planning & Reasoning.K=500": -16.27358490566038,
    "mixture_of_rewards.Planning & Reasoning.K=500": 15.436731217571717,
    "haiku_reward.Math & Data Analysis.K=500": 18.51851851851852,
    "llama_reward.Math & Data Analysis.K=500": 55.208333333333336,
    "gpt4t_reward.Math & Data Analysis.K=500": -20.74688796680498,
    "mixture_of_rewards.Math & Data Analysis.K=500": 17.65998796168229,
    "haiku_reward.Information/Advice seeking.K=500": 11.757105943152455,
    "llama_reward.Information/Advice seeking.K=500": 32.68733850129199,
    "gpt4t_reward.Information/Advice seeking.K=500": -10.841836734693878,
    "mixture_of_rewards.Information/Advice seeking.K=500": 11.200869236583522,
    "haiku_reward.Coding & Debugging.K=500": 11.021505376344086,
    "llama_reward.Coding & Debugging.K=500": 54.81283422459893,
    "gpt4t_reward.Coding & Debugging.K=500": -27.225130890052355,
    "mixture_of_rewards.Coding & Debugging.K=500": 12.869736236963552,
    "haiku_reward.task_macro.K=500": 15.85709763449423,
    "llama_reward.task_macro.K=500": 46.640007466919506,
    "gpt4t_reward.task_macro.K=500": -18.764218661230462,
    "mixture_of_rewards.K=500": 13.460286458333334,
    "task_macro_reward.K=500": 14.577628813394426,
    "WB_score.Creative Tasks": 53.59173126614987,
    "WB_score.Planning & Reasoning": 50.62874251497006,
    "WB_score.Math & Data Analysis": 44.523809523809526,
    "WB_score.Information/Advice seeking": 51.811414392059554,
    "WB_score.Coding & Debugging": 44.43396226415095,
    "WB_score": 50.04887585532748,
    "WB_score.task_macro": 48.21191935259587,
    "Length": 2896.965786901271,
    "Rank_ScoreMacro": 17,
    "Rank_TaskMacroReward.K": 13,
    "Rank_Avg": 15.0,
    "RewardScore_Avg": 31.39477408299515,
    "WB_Elo": 1184.0251150954687
  },
  "gemma-2-27b-it@together": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 53.626943005181346,
    "WB_score.Planning & Reasoning": 50.55472263868065,
    "WB_score.Math & Data Analysis": 43.919999999999995,
    "WB_score.Information/Advice seeking": 50.49504950495049,
    "WB_score.Coding & Debugging": 47.01421800947868,
    "WB_score": 49.39453125,
    "WB_score.task_macro": 48.54019672452688,
    "Length": 2924.5455435847207,
    "Rank_ScoreMacro": 16,
    "Rank_TaskMacroReward.K": 31,
    "Rank_Avg": 23.5,
    "RewardScore_Avg": 24.27009836226344,
    "WB_Elo": 1182.173597976001
  },
  "Mistral-Nemo-Instruct-2407": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 54.573643410852725,
    "WB_score.Planning & Reasoning": 47.41405082212257,
    "WB_score.Math & Data Analysis": 35.63492063492063,
    "WB_score.Information/Advice seeking": 51.93069306930694,
    "WB_score.Coding & Debugging": 39.71563981042655,
    "WB_score": 46.86217008797654,
    "WB_score.task_macro": 44.37513167010813,
    "Length": 3318.2130987292276,
    "Rank_ScoreMacro": 26,
    "Rank_TaskMacroReward.K": 32,
    "Rank_Avg": 29.0,
    "RewardScore_Avg": 22.187565835054066,
    "WB_Elo": 1166.8049601578437
  },
  "Llama-3-8B-Magpie-Align-v0.1": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 19.140625,
    "llama_reward.K=500": 42.67578125,
    "gpt4t_reward.K=500": -14.404296875,
    "haiku_reward.Creative Tasks.K=500": 34.9002849002849,
    "llama_reward.Creative Tasks.K=500": 42.40687679083094,
    "gpt4t_reward.Creative Tasks.K=500": -6.775067750677506,
    "mixture_of_rewards.Creative Tasks.K=500": 23.510697980146116,
    "haiku_reward.Planning & Reasoning.K=500": 15.977742448330684,
    "llama_reward.Planning & Reasoning.K=500": 44.56,
    "gpt4t_reward.Planning & Reasoning.K=500": -16.27725856697819,
    "mixture_of_rewards.Planning & Reasoning.K=500": 14.7534946271175,
    "haiku_reward.Math & Data Analysis.K=500": 8.333333333333332,
    "llama_reward.Math & Data Analysis.K=500": 50.40816326530613,
    "gpt4t_reward.Math & Data Analysis.K=500": -31.22448979591837,
    "mixture_of_rewards.Math & Data Analysis.K=500": 9.17233560090703,
    "haiku_reward.Information/Advice seeking.K=500": 25.96401028277635,
    "llama_reward.Information/Advice seeking.K=500": 47.30077120822622,
    "gpt4t_reward.Information/Advice seeking.K=500": -0.2544529262086514,
    "mixture_of_rewards.Information/Advice seeking.K=500": 24.336776188264636,
    "haiku_reward.Coding & Debugging.K=500": 4.619565217391304,
    "llama_reward.Coding & Debugging.K=500": 53.53260869565217,
    "gpt4t_reward.Coding & Debugging.K=500": -29.84293193717277,
    "mixture_of_rewards.Coding & Debugging.K=500": 9.436413991956902,
    "haiku_reward.task_macro.K=500": 14.948024858465372,
    "llama_reward.task_macro.K=500": 48.35851388135926,
    "gpt4t_reward.task_macro.K=500": -19.463810841284698,
    "mixture_of_rewards.K=500": 15.804036458333334,
    "task_macro_reward.K=500": 14.614242632846645,
    "WB_score.Creative Tasks": 49.19896640826874,
    "WB_score.Planning & Reasoning": 42.7245508982036,
    "WB_score.Math & Data Analysis": 29.76000000000001,
    "WB_score.Information/Advice seeking": 48.910891089108915,
    "WB_score.Coding & Debugging": 33.74407582938389,
    "WB_score": 42.44618395303327,
    "WB_score.task_macro": 39.290196827463255,
    "Length": 3107.77397260274,
    "Rank_ScoreMacro": 29,
    "Rank_TaskMacroReward.K": 12,
    "Rank_Avg": 20.5,
    "RewardScore_Avg": 26.95221973015495,
    "WB_Elo": 1151.402258570742
  },
  "Llama-3-Instruct-8B-SimPO-v0.2": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 51.83462532299741,
    "WB_score.Planning & Reasoning": 40.71856287425149,
    "WB_score.Math & Data Analysis": 24.38247011952191,
    "WB_score.Information/Advice seeking": 47.871287128712865,
    "WB_score.Coding & Debugging": 31.50943396226415,
    "WB_score": 41.50537634408602,
    "WB_score.task_macro": 37.1554198259368,
    "Length": 2533.764418377322,
    "Rank_ScoreMacro": 34,
    "Rank_TaskMacroReward.K": 33,
    "Rank_Avg": 33.5,
    "RewardScore_Avg": 18.5777099129684,
    "WB_Elo": 1148.0879185900626
  },
  "glm-4-9b-chat": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -2.346041055718475,
    "llama_reward.K=500": 22.14076246334311,
    "gpt4t_reward.K=500": -31.702544031311152,
    "haiku_reward.Creative Tasks.K=500": 9.15915915915916,
    "llama_reward.Creative Tasks.K=500": 16.565349544072948,
    "gpt4t_reward.Creative Tasks.K=500": -27.84256559766764,
    "mixture_of_rewards.Creative Tasks.K=500": -0.7060189648118443,
    "haiku_reward.Planning & Reasoning.K=500": -3.61952861952862,
    "llama_reward.Planning & Reasoning.K=500": 29.506802721088437,
    "gpt4t_reward.Planning & Reasoning.K=500": -35.41666666666667,
    "mixture_of_rewards.Planning & Reasoning.K=500": -3.1764641883689513,
    "haiku_reward.Math & Data Analysis.K=500": -10.91703056768559,
    "llama_reward.Math & Data Analysis.K=500": 32.23684210526316,
    "gpt4t_reward.Math & Data Analysis.K=500": -48.89867841409692,
    "mixture_of_rewards.Math & Data Analysis.K=500": -9.192955625506452,
    "haiku_reward.Information/Advice seeking.K=500": -5.347593582887701,
    "llama_reward.Information/Advice seeking.K=500": 19.623655913978492,
    "gpt4t_reward.Information/Advice seeking.K=500": -25.265957446808514,
    "mixture_of_rewards.Information/Advice seeking.K=500": -3.6632983719059076,
    "haiku_reward.Coding & Debugging.K=500": -8.571428571428571,
    "llama_reward.Coding & Debugging.K=500": 45.689655172413794,
    "gpt4t_reward.Coding & Debugging.K=500": -50.84269662921348,
    "mixture_of_rewards.Coding & Debugging.K=500": -4.574823342742751,
    "haiku_reward.task_macro.K=500": -5.386703718730164,
    "llama_reward.task_macro.K=500": 31.41743814308659,
    "gpt4t_reward.task_macro.K=500": -39.91444914060786,
    "mixture_of_rewards.K=500": -3.969274207895507,
    "task_macro_reward.K=500": -4.627904905417144,
    "WB_score.Creative Tasks": 47.751937984496124,
    "WB_score.Planning & Reasoning": 42.48502994011975,
    "WB_score.Math & Data Analysis": 29.800796812748995,
    "WB_score.Information/Advice seeking": 46.28712871287128,
    "WB_score.Coding & Debugging": 35.37735849056604,
    "WB_score": 41.17302052785924,
    "WB_score.task_macro": 39.09896797431742,
    "Length": 3692.043010752688,
    "Rank_ScoreMacro": 30,
    "Rank_TaskMacroReward.K": 39,
    "Rank_Avg": 34.5,
    "RewardScore_Avg": 17.235531534450136,
    "WB_Elo": 1146.685826739111
  },
  "SELM-Llama-3-8B-Instruct-iter-3": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 6.93359375,
    "llama_reward.K=500": 32.666015625,
    "gpt4t_reward.K=500": -29.423264907135877,
    "haiku_reward.Creative Tasks.K=500": 22.268907563025213,
    "llama_reward.Creative Tasks.K=500": 36.51685393258427,
    "gpt4t_reward.Creative Tasks.K=500": -20.689655172413794,
    "mixture_of_rewards.Creative Tasks.K=500": 12.698702107731895,
    "haiku_reward.Planning & Reasoning.K=500": 6.189710610932476,
    "llama_reward.Planning & Reasoning.K=500": 34.967845659163984,
    "gpt4t_reward.Planning & Reasoning.K=500": -30.410742496050553,
    "mixture_of_rewards.Planning & Reasoning.K=500": 3.5822712580153038,
    "haiku_reward.Math & Data Analysis.K=500": -6.557377049180328,
    "llama_reward.Math & Data Analysis.K=500": 37.242798353909464,
    "gpt4t_reward.Math & Data Analysis.K=500": -43.18181818181818,
    "mixture_of_rewards.Math & Data Analysis.K=500": -4.165465625696348,
    "haiku_reward.Information/Advice seeking.K=500": 9.02061855670103,
    "llama_reward.Information/Advice seeking.K=500": 32.86082474226804,
    "gpt4t_reward.Information/Advice seeking.K=500": -19.642857142857142,
    "mixture_of_rewards.Information/Advice seeking.K=500": 7.412862052037311,
    "haiku_reward.Coding & Debugging.K=500": -8.806818181818182,
    "llama_reward.Coding & Debugging.K=500": 42.737430167597765,
    "gpt4t_reward.Coding & Debugging.K=500": -57.49999999999999,
    "mixture_of_rewards.Coding & Debugging.K=500": -7.856462671406803,
    "haiku_reward.task_macro.K=500": 1.6991907760528249,
    "llama_reward.task_macro.K=500": 37.3217765600747,
    "gpt4t_reward.task_macro.K=500": -37.50467720952234,
    "mixture_of_rewards.K=500": 3.3921148226213744,
    "task_macro_reward.K=500": 0.5054300422017283,
    "WB_score.Creative Tasks": 51.05943152454781,
    "WB_score.Planning & Reasoning": 39.78978978978979,
    "WB_score.Math & Data Analysis": 23.505976095617527,
    "WB_score.Information/Advice seeking": 46.05459057071961,
    "WB_score.Coding & Debugging": 27.333333333333325,
    "WB_score": 39.96078431372549,
    "WB_score.task_macro": 35.25906077680738,
    "Length": 2913.1470588235293,
    "Rank_ScoreMacro": 37,
    "Rank_TaskMacroReward.K": 22,
    "Rank_Avg": 29.5,
    "RewardScore_Avg": 17.882245409504556,
    "WB_Elo": 1141.2979653779491
  },
  "Yi-1.5-9B-Chat": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -0.44031311154598823,
    "llama_reward.K=500": 22.825024437927663,
    "gpt4t_reward.K=500": -31.34765625,
    "haiku_reward.Creative Tasks.K=500": 3.672316384180791,
    "llama_reward.Creative Tasks.K=500": 16.80911680911681,
    "gpt4t_reward.Creative Tasks.K=500": -32.123655913978496,
    "mixture_of_rewards.Creative Tasks.K=500": -3.8807409068936316,
    "haiku_reward.Planning & Reasoning.K=500": 2.454991816693944,
    "llama_reward.Planning & Reasoning.K=500": 32.37704918032787,
    "gpt4t_reward.Planning & Reasoning.K=500": -30.206677265500797,
    "mixture_of_rewards.Planning & Reasoning.K=500": 1.5417879105070078,
    "haiku_reward.Math & Data Analysis.K=500": 4.05982905982906,
    "llama_reward.Math & Data Analysis.K=500": 44.04255319148936,
    "gpt4t_reward.Math & Data Analysis.K=500": -35.16949152542373,
    "mixture_of_rewards.Math & Data Analysis.K=500": 4.310963575298229,
    "haiku_reward.Information/Advice seeking.K=500": -3.350515463917526,
    "llama_reward.Information/Advice seeking.K=500": 19.170984455958546,
    "gpt4t_reward.Information/Advice seeking.K=500": -26.717557251908396,
    "mixture_of_rewards.Information/Advice seeking.K=500": -3.6323627532891254,
    "haiku_reward.Coding & Debugging.K=500": -8.938547486033519,
    "llama_reward.Coding & Debugging.K=500": 39.166666666666664,
    "gpt4t_reward.Coding & Debugging.K=500": -48.93048128342246,
    "mixture_of_rewards.Coding & Debugging.K=500": -6.234120700929772,
    "haiku_reward.task_macro.K=500": -0.9939671437248755,
    "llama_reward.task_macro.K=500": 32.895788367738916,
    "gpt4t_reward.task_macro.K=500": -35.82967065421018,
    "mixture_of_rewards.K=500": -2.987648307872776,
    "task_macro_reward.K=500": -1.3092831433987147,
    "WB_score.Creative Tasks": 45.5958549222798,
    "WB_score.Planning & Reasoning": 42.37237237237237,
    "WB_score.Math & Data Analysis": 32.20883534136546,
    "WB_score.Information/Advice seeking": 42.62376237623762,
    "WB_score.Coding & Debugging": 34.97630331753555,
    "WB_score": 39.8435972629521,
    "WB_score.task_macro": 38.66535351517231,
    "Length": 3468.23431372549,
    "Rank_ScoreMacro": 33,
    "Rank_TaskMacroReward.K": 36,
    "Rank_Avg": 34.5,
    "RewardScore_Avg": 18.6780351858868,
    "WB_Elo": 1140.0225599844637
  },
  "Llama-3-Instruct-8B-SimPO-ExPO": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 17.333984375,
    "llama_reward.K=500": 41.796875,
    "gpt4t_reward.K=500": -14.6484375,
    "haiku_reward.Creative Tasks.K=500": 32.86908077994429,
    "llama_reward.Creative Tasks.K=500": 42.857142857142854,
    "gpt4t_reward.Creative Tasks.K=500": -4.617414248021108,
    "mixture_of_rewards.Creative Tasks.K=500": 23.702936463022013,
    "haiku_reward.Planning & Reasoning.K=500": 15.80188679245283,
    "llama_reward.Planning & Reasoning.K=500": 44.38291139240506,
    "gpt4t_reward.Planning & Reasoning.K=500": -16.69242658423493,
    "mixture_of_rewards.Planning & Reasoning.K=500": 14.497457200207656,
    "haiku_reward.Math & Data Analysis.K=500": -3.4412955465587043,
    "llama_reward.Math & Data Analysis.K=500": 40.447154471544714,
    "gpt4t_reward.Math & Data Analysis.K=500": -35.56910569105691,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.478917744643032,
    "haiku_reward.Information/Advice seeking.K=500": 24.42455242966752,
    "llama_reward.Information/Advice seeking.K=500": 45.52429667519181,
    "gpt4t_reward.Information/Advice seeking.K=500": 0.0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 23.316283034953113,
    "haiku_reward.Coding & Debugging.K=500": 6.084656084656085,
    "llama_reward.Coding & Debugging.K=500": 52.38095238095239,
    "gpt4t_reward.Coding & Debugging.K=500": -36.340206185567006,
    "mixture_of_rewards.Coding & Debugging.K=500": 7.375134093347154,
    "haiku_reward.task_macro.K=500": 12.351544792010571,
    "llama_reward.task_macro.K=500": 45.678690131201435,
    "gpt4t_reward.task_macro.K=500": -21.930232374172608,
    "mixture_of_rewards.K=500": 14.827473958333334,
    "task_macro_reward.K=500": 12.033334183013134,
    "WB_score.Creative Tasks": 49.14728682170542,
    "WB_score.Planning & Reasoning": 39.46107784431138,
    "WB_score.Math & Data Analysis": 21.195219123505975,
    "WB_score.Information/Advice seeking": 47.32673267326733,
    "WB_score.Coding & Debugging": 28.584905660377355,
    "WB_score": 39.687194525904204,
    "WB_score.task_macro": 35.01502977266739,
    "Length": 2480.6490713587486,
    "Rank_ScoreMacro": 38,
    "Rank_TaskMacroReward.K": 18,
    "Rank_Avg": 28.0,
    "RewardScore_Avg": 23.52418197784026,
    "WB_Elo": 1144.9796209560836
  },
  "Starling-LM-7B-beta-ExPO": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -3.41796875,
    "llama_reward.K=500": 22.265625,
    "gpt4t_reward.K=500": -34.619140625,
    "haiku_reward.Creative Tasks.K=500": 10.364145658263306,
    "llama_reward.Creative Tasks.K=500": 21.207865168539325,
    "gpt4t_reward.Creative Tasks.K=500": -25.989445910290236,
    "mixture_of_rewards.Creative Tasks.K=500": 1.8608549721707988,
    "haiku_reward.Planning & Reasoning.K=500": -4.754358161648177,
    "llama_reward.Planning & Reasoning.K=500": 24.840764331210192,
    "gpt4t_reward.Planning & Reasoning.K=500": -34.984520123839005,
    "mixture_of_rewards.Planning & Reasoning.K=500": -4.966037984758997,
    "haiku_reward.Math & Data Analysis.K=500": -17.959183673469386,
    "llama_reward.Math & Data Analysis.K=500": 29.508196721311474,
    "gpt4t_reward.Math & Data Analysis.K=500": -50.614754098360656,
    "mixture_of_rewards.Math & Data Analysis.K=500": -13.02191368350619,
    "haiku_reward.Information/Advice seeking.K=500": -2.6923076923076925,
    "llama_reward.Information/Advice seeking.K=500": 20.64102564102564,
    "gpt4t_reward.Information/Advice seeking.K=500": -25.126262626262623,
    "mixture_of_rewards.Information/Advice seeking.K=500": -2.3925148925148925,
    "haiku_reward.Coding & Debugging.K=500": -15.44502617801047,
    "llama_reward.Coding & Debugging.K=500": 34.81675392670157,
    "gpt4t_reward.Coding & Debugging.K=500": -50.75757575757576,
    "mixture_of_rewards.Coding & Debugging.K=500": -10.461949336294886,
    "haiku_reward.task_macro.K=500": -8.43064674487196,
    "llama_reward.task_macro.K=500": 27.403115022892642,
    "gpt4t_reward.task_macro.K=500": -39.92248292104657,
    "mixture_of_rewards.K=500": -5.257161458333333,
    "task_macro_reward.K=500": -6.983338214341964,
    "WB_score.Creative Tasks": 44.30051813471502,
    "WB_score.Planning & Reasoning": 36.31736526946108,
    "WB_score.Math & Data Analysis": 18.571428571428577,
    "WB_score.Information/Advice seeking": 42.871287128712865,
    "WB_score.Coding & Debugging": 25.308056872037916,
    "WB_score": 35.01466275659824,
    "WB_score.task_macro": 31.559353823619887,
    "Length": 2835.826810176125,
    "Rank_ScoreMacro": 40,
    "Rank_TaskMacroReward.K": 41,
    "Rank_Avg": 40.5,
    "RewardScore_Avg": 12.288007804638962,
    "WB_Elo": 1125.6065314200982
  },
  "gemma-2-2b-it": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": 0,
    "llama_reward.K=500": 0,
    "gpt4t_reward.K=500": 0,
    "haiku_reward.Creative Tasks.K=500": 0,
    "llama_reward.Creative Tasks.K=500": 0,
    "gpt4t_reward.Creative Tasks.K=500": 0,
    "mixture_of_rewards.Creative Tasks.K=500": 0.0,
    "haiku_reward.Planning & Reasoning.K=500": 0,
    "llama_reward.Planning & Reasoning.K=500": 0,
    "gpt4t_reward.Planning & Reasoning.K=500": 0,
    "mixture_of_rewards.Planning & Reasoning.K=500": 0.0,
    "haiku_reward.Math & Data Analysis.K=500": 0,
    "llama_reward.Math & Data Analysis.K=500": 0,
    "gpt4t_reward.Math & Data Analysis.K=500": 0,
    "mixture_of_rewards.Math & Data Analysis.K=500": 0.0,
    "haiku_reward.Information/Advice seeking.K=500": 0,
    "llama_reward.Information/Advice seeking.K=500": 0,
    "gpt4t_reward.Information/Advice seeking.K=500": 0,
    "mixture_of_rewards.Information/Advice seeking.K=500": 0.0,
    "haiku_reward.Coding & Debugging.K=500": 0,
    "llama_reward.Coding & Debugging.K=500": 0,
    "gpt4t_reward.Coding & Debugging.K=500": 0,
    "mixture_of_rewards.Coding & Debugging.K=500": 0.0,
    "haiku_reward.task_macro.K=500": 0,
    "llama_reward.task_macro.K=500": 0,
    "gpt4t_reward.task_macro.K=500": 0,
    "mixture_of_rewards.K=500": 0.0,
    "task_macro_reward.K=500": 0.0,
    "WB_score.Creative Tasks": 43.61757105943152,
    "WB_score.Planning & Reasoning": 33.811659192825104,
    "WB_score.Math & Data Analysis": 15.79365079365079,
    "WB_score.Information/Advice seeking": 39.90099009900991,
    "WB_score.Coding & Debugging": 17.904761904761912,
    "WB_score": 32.72015655577299,
    "WB_score.task_macro": 27.826043214654263,
    "Length": 3589.3894324853227,
    "Rank_ScoreMacro": 50,
    "Rank_TaskMacroReward.K": 34,
    "Rank_Avg": 42.0,
    "RewardScore_Avg": 13.913021607327131,
    "WB_Elo": 1114.9711016640829
  },
  "neo_7b_instruct_v0.1": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -16.455078125,
    "llama_reward.K=500": 7.275390625,
    "gpt4t_reward.K=500": -44.76003917727718,
    "haiku_reward.Creative Tasks.K=500": 0.5763688760806917,
    "llama_reward.Creative Tasks.K=500": 11.19186046511628,
    "gpt4t_reward.Creative Tasks.K=500": -38.04945054945055,
    "mixture_of_rewards.Creative Tasks.K=500": -8.760407069417859,
    "haiku_reward.Planning & Reasoning.K=500": -17.93831168831169,
    "llama_reward.Planning & Reasoning.K=500": 12.561174551386623,
    "gpt4t_reward.Planning & Reasoning.K=500": -45.53429027113238,
    "mixture_of_rewards.Planning & Reasoning.K=500": -16.970475802685815,
    "haiku_reward.Math & Data Analysis.K=500": -31.171548117154813,
    "llama_reward.Math & Data Analysis.K=500": 12.552301255230125,
    "gpt4t_reward.Math & Data Analysis.K=500": -58.89830508474576,
    "mixture_of_rewards.Math & Data Analysis.K=500": -25.839183982223478,
    "haiku_reward.Information/Advice seeking.K=500": -15.44502617801047,
    "llama_reward.Information/Advice seeking.K=500": 3.6458333333333335,
    "gpt4t_reward.Information/Advice seeking.K=500": -37.91773778920309,
    "mixture_of_rewards.Information/Advice seeking.K=500": -16.57231021129341,
    "haiku_reward.Coding & Debugging.K=500": -42.04545454545455,
    "llama_reward.Coding & Debugging.K=500": 2.2857142857142856,
    "gpt4t_reward.Coding & Debugging.K=500": -70.6043956043956,
    "mixture_of_rewards.Coding & Debugging.K=500": -36.78804528804529,
    "haiku_reward.task_macro.K=500": -24.7256507589116,
    "llama_reward.task_macro.K=500": 8.30341421771882,
    "gpt4t_reward.task_macro.K=500": -52.954671799112276,
    "mixture_of_rewards.K=500": -17.979908892425726,
    "task_macro_reward.K=500": -23.125636113435018,
    "WB_score.Creative Tasks": 39.48186528497409,
    "WB_score.Planning & Reasoning": 31.44992526158445,
    "WB_score.Math & Data Analysis": 15.0,
    "WB_score.Information/Advice seeking": 36.33663366336634,
    "WB_score.Coding & Debugging": 14.02843601895734,
    "WB_score": 29.19921875,
    "WB_score.task_macro": 25.019233576987165,
    "Length": 3735.800586510264,
    "Rank_ScoreMacro": 53,
    "Rank_TaskMacroReward.K": 52,
    "Rank_Avg": 52.5,
    "RewardScore_Avg": 0.9467987317760738,
    "WB_Elo": 1104.2844374018302
  },
  "neo_7b_instruct_v0.1-ExPO": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -18.994140625,
    "llama_reward.K=500": 2.4926686217008798,
    "gpt4t_reward.K=500": -44.72140762463343,
    "haiku_reward.Creative Tasks.K=500": 0.2932551319648094,
    "llama_reward.Creative Tasks.K=500": 11.143695014662756,
    "gpt4t_reward.Creative Tasks.K=500": -36.37640449438202,
    "mixture_of_rewards.Creative Tasks.K=500": -8.313151449251485,
    "haiku_reward.Planning & Reasoning.K=500": -24.503311258278146,
    "llama_reward.Planning & Reasoning.K=500": 5.258764607679465,
    "gpt4t_reward.Planning & Reasoning.K=500": -47.642276422764226,
    "mixture_of_rewards.Planning & Reasoning.K=500": -22.295607691120967,
    "haiku_reward.Math & Data Analysis.K=500": -37.65690376569037,
    "llama_reward.Math & Data Analysis.K=500": 3.3472803347280333,
    "gpt4t_reward.Math & Data Analysis.K=500": -63.17991631799163,
    "mixture_of_rewards.Math & Data Analysis.K=500": -32.49651324965132,
    "haiku_reward.Information/Advice seeking.K=500": -17.11229946524064,
    "llama_reward.Information/Advice seeking.K=500": 3.4759358288770055,
    "gpt4t_reward.Information/Advice seeking.K=500": -39.55026455026455,
    "mixture_of_rewards.Information/Advice seeking.K=500": -17.728876062209395,
    "haiku_reward.Coding & Debugging.K=500": -53.25443786982249,
    "llama_reward.Coding & Debugging.K=500": -10.526315789473683,
    "gpt4t_reward.Coding & Debugging.K=500": -73.29545454545455,
    "mixture_of_rewards.Coding & Debugging.K=500": -45.69206940158357,
    "haiku_reward.task_macro.K=500": -31.061407833424052,
    "llama_reward.task_macro.K=500": 1.0403454182051357,
    "gpt4t_reward.task_macro.K=500": -55.200627513295686,
    "mixture_of_rewards.K=500": -20.407626542644184,
    "task_macro_reward.K=500": -28.407229976171536,
    "WB_score.Creative Tasks": 38.549222797927456,
    "WB_score.Planning & Reasoning": 28.669656203288483,
    "WB_score.Math & Data Analysis": 12.589641434262955,
    "WB_score.Information/Advice seeking": 34.85148514851485,
    "WB_score.Coding & Debugging": 12.76190476190477,
    "WB_score": 27.624633431085037,
    "WB_score.task_macro": 23.114172189706185,
    "Length": 4107.917808219178,
    "Rank_ScoreMacro": 56,
    "Rank_TaskMacroReward.K": 57,
    "Rank_Avg": 56.5,
    "RewardScore_Avg": -2.6465288932326754,
    "WB_Elo": 1104.5166529743904
  },
  "Yi-1.5-6B-Chat": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -21.309872922776147,
    "llama_reward.K=500": 1.953125,
    "gpt4t_reward.K=500": -47.607421875,
    "haiku_reward.Creative Tasks.K=500": -17.8125,
    "llama_reward.Creative Tasks.K=500": -7.8125,
    "gpt4t_reward.Creative Tasks.K=500": -50.297619047619044,
    "mixture_of_rewards.Creative Tasks.K=500": -25.30753968253968,
    "haiku_reward.Planning & Reasoning.K=500": -24.829931972789115,
    "llama_reward.Planning & Reasoning.K=500": 7.627118644067797,
    "gpt4t_reward.Planning & Reasoning.K=500": -51.83946488294314,
    "mixture_of_rewards.Planning & Reasoning.K=500": -23.01409273722149,
    "haiku_reward.Math & Data Analysis.K=500": -24.57264957264957,
    "llama_reward.Math & Data Analysis.K=500": 21.729957805907173,
    "gpt4t_reward.Math & Data Analysis.K=500": -55.55555555555556,
    "mixture_of_rewards.Math & Data Analysis.K=500": -19.466082440765984,
    "haiku_reward.Information/Advice seeking.K=500": -22.48603351955307,
    "llama_reward.Information/Advice seeking.K=500": -3.081232492997199,
    "gpt4t_reward.Information/Advice seeking.K=500": -45.30386740331492,
    "mixture_of_rewards.Information/Advice seeking.K=500": -23.62371113862173,
    "haiku_reward.Coding & Debugging.K=500": -42.737430167597765,
    "llama_reward.Coding & Debugging.K=500": 6.629834254143646,
    "gpt4t_reward.Coding & Debugging.K=500": -70.0,
    "mixture_of_rewards.Coding & Debugging.K=500": -35.36919863781804,
    "haiku_reward.task_macro.K=500": -28.379500502694317,
    "llama_reward.task_macro.K=500": 7.017678854510227,
    "gpt4t_reward.task_macro.K=500": -56.20665194432215,
    "mixture_of_rewards.K=500": -22.32138993259205,
    "task_macro_reward.K=500": -25.856157864168747,
    "WB_score.Creative Tasks": 31.088082901554408,
    "WB_score.Planning & Reasoning": 27.2972972972973,
    "WB_score.Math & Data Analysis": 16.799999999999997,
    "WB_score.Information/Advice seeking": 31.414392059553347,
    "WB_score.Coding & Debugging": 16.587677725118475,
    "WB_score": 25.278592375366564,
    "WB_score.task_macro": 23.318116689149882,
    "Length": 3899.4686274509804,
    "Rank_ScoreMacro": 55,
    "Rank_TaskMacroReward.K": 56,
    "Rank_Avg": 55.5,
    "RewardScore_Avg": -1.2690205875094325,
    "WB_Elo": 1099.4947697983446
  },
  "reka-edge": {
    "Arena Elo (hard-en) - latest": "-",
    "Arena-Hard v0.1": "-",
    "AE2.0 LC": "-",
    "AE2.0": "-",
    "haiku_reward.K=500": -18.994140625,
    "llama_reward.K=500": 6.15234375,
    "gpt4t_reward.K=500": -45.849609375,
    "haiku_reward.Creative Tasks.K=500": -6.502890173410404,
    "llama_reward.Creative Tasks.K=500": 4.899135446685879,
    "gpt4t_reward.Creative Tasks.K=500": -40.21739130434783,
    "mixture_of_rewards.Creative Tasks.K=500": -13.940382010357451,
    "haiku_reward.Planning & Reasoning.K=500": -26.307189542483663,
    "llama_reward.Planning & Reasoning.K=500": 6.290849673202614,
    "gpt4t_reward.Planning & Reasoning.K=500": -51.04,
    "mixture_of_rewards.Planning & Reasoning.K=500": -23.685446623093682,
    "haiku_reward.Math & Data Analysis.K=500": -39.166666666666664,
    "llama_reward.Math & Data Analysis.K=500": 15.481171548117153,
    "gpt4t_reward.Math & Data Analysis.K=500": -62.39495798319328,
    "mixture_of_rewards.Math & Data Analysis.K=500": -28.693484367247596,
    "haiku_reward.Information/Advice seeking.K=500": -18.096514745308312,
    "llama_reward.Information/Advice seeking.K=500": 0.267379679144385,
    "gpt4t_reward.Information/Advice seeking.K=500": -39.257294429708224,
    "mixture_of_rewards.Information/Advice seeking.K=500": -19.028809831957386,
    "haiku_reward.Coding & Debugging.K=500": -32.27513227513227,
    "llama_reward.Coding & Debugging.K=500": 15.526315789473685,
    "gpt4t_reward.Coding & Debugging.K=500": -60.71428571428571,
    "mixture_of_rewards.Coding & Debugging.K=500": -25.8210340666481,
    "haiku_reward.task_macro.K=500": -27.20387370197327,
    "llama_reward.task_macro.K=500": 9.55846965456079,
    "gpt4t_reward.task_macro.K=500": -52.97673296852747,
    "mixture_of_rewards.K=500": -19.563802083333332,
    "task_macro_reward.K=500": -23.540712338646653,
    "WB_score.Creative Tasks": 36.180371352785144,
    "WB_score.Planning & Reasoning": 25.007727975270484,
    "WB_score.Math & Data Analysis": 8.89795918367346,
    "WB_score.Information/Advice seeking": 34.3896103896104,
    "WB_score.Coding & Debugging": 13.526570048309186,
    "WB_score": 23.186705767350926,
    "WB_score.task_macro": 21.252257932999665,
    "Length": 2417.351106639839,
    "Rank_ScoreMacro": 57,
    "Rank_TaskMacroReward.K": 53,
    "Rank_Avg": 55.0,
    "RewardScore_Avg": -1.1442272028234939,
    "WB_Elo": 1098.4979869242243
  }
}